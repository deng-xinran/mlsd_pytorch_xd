using config:  mlsd_pytorch/configs/mobilev2_mlsd_tiny_512_base2_bsize16.yaml
datasets:
  input_size: 512
  name: wireframe
  with_centermap_extend: False
decode:
  len_thresh: 5
  score_thresh: 0.05
  top_k: 500
loss:
  focal_loss_level: 0
  loss_type: 1*L1
  loss_weight_dict_list: [{'tp_center_loss': 10.0, 'sol_center_loss': 1.0, 'tp_match_loss': 1.0}]
  match_sap_thresh: 5.0
  with_focal_loss: True
  with_match_loss: False
  with_sol_loss: True
model:
  model_name: mobilev2_mlsd
  num_classes: 1
  with_deconv: True
sys:
  cpu: False
  gpus: 1
  num_workers: 8
train:
  adam_epsilon: 1e-06
  batch_size: 16
  cache_to_mem: False
  data_cache_dir: ./data/wireframe_cache/
  device_ids: [0]
  device_ids_str: 0
  do_train: True
  dropout: 0.1
  early_stop_n: 200
  gradient_accumulation_steps: 1
  img_dir: ./data/wireframe_raw/images/
  label_fn: ./data/wireframe_raw/train.json
  learning_rate: 0.003
  load_from: 
  log_steps: 50
  lr_decay_gamma: 0.2
  milestones: [50, 100, 150]
  milestones_in_epo: True
  num_train_epochs: 155
  num_workers: 8
  save_dir: ./workdir/models/mobilev2_mlsd_tiny_512_bsize242023-10-10T13:06:50.825754/
  use_step_lr_policy: True
  warmup_steps: 100
  weight_decay: 1e-06
  with_cache: False
val:
  batch_size: 8
  img_dir: ./data/wireframe_raw/images/
  label_fn: ./data/wireframe_raw/valid.json
  val_after_epoch: 50
==> load label..
==> valid samples:  48
==> load label..
==> valid samples:  15
MobileV2_MLSD(
  (backbone): MobileNetV2(
    (features): Sequential(
      (0): ConvBNReLU(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (block12): BlockTypeA(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (block13): BlockTypeB(
    (conv1): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (block14): BlockTypeA(
    (conv1): Sequential(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (block15): BlockTypeB(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (block16): BlockTypeC(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(5, 5), dilation=(5, 5))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv3): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
  )
  (block17): BilinearConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
)
===> loss weight:  {'tp_center_loss': 10.0, 'tp_displacement_loss': 1.0, 'tp_len_loss': 1.0, 'tp_angle_loss': 1.0, 'tp_match_loss': 1.0, 'tp_centerness_loss': 1.0, 'sol_center_loss': 1.0, 'sol_displacement_loss': 1.0, 'sol_len_loss': 1.0, 'sol_angle_loss': 1.0, 'sol_match_loss': 1.0, 'sol_centerness_loss': 1.0, 'line_seg_loss': 1.0, 'junc_seg_loss': 1.0}
==>step: 156, f_score: 0.38249874114990234, recall: 0.5318382382392883, precision:0.3134336471557617, sAP10: 0.009389671361502346
 
epo: 51, steps: 156 ,sAP10 : 0.0094 , best sAP10: 0.0094
{'fscore': 0.38249874, 'recall': 0.53183824, 'precision': 0.31343365, 'sAP10': 0.009389671361502346}
====================================================================================================
==>step: 159, f_score: 0.37788525223731995, recall: 0.5202644467353821, precision:0.339712917804718, sAP10: 0.5432079305030125
 
epo: 52, steps: 159 ,sAP10 : 0.5432 , best sAP10: 0.5432
{'fscore': 0.37788525, 'recall': 0.52026445, 'precision': 0.33971292, 'sAP10': 0.5432079305030125}
====================================================================================================
==>step: 162, f_score: 0.3725793659687042, recall: 0.49292895197868347, precision:0.3377784788608551, sAP10: 4.500000000000001
 
epo: 53, steps: 162 ,sAP10 : 4.5000 , best sAP10: 4.5000
{'fscore': 0.37257937, 'recall': 0.49292895, 'precision': 0.33777848, 'sAP10': 4.500000000000001}
====================================================================================================
==>step: 165, f_score: 0.32798150181770325, recall: 0.43891340494155884, precision:0.2881881892681122, sAP10: 1.7171717171717171
 
epo: 54, steps: 165 ,sAP10 : 1.7172 , best sAP10: 4.5000
{'fscore': 0.3279815, 'recall': 0.4389134, 'precision': 0.2881882, 'sAP10': 1.7171717171717171}
====================================================================================================
==>step: 168, f_score: 0.336770623922348, recall: 0.45618900656700134, precision:0.2834338843822479, sAP10: 0.6429613746686917
 
epo: 55, steps: 168 ,sAP10 : 0.6430 , best sAP10: 4.5000
{'fscore': 0.33677062, 'recall': 0.456189, 'precision': 0.28343388, 'sAP10': 0.6429613746686917}
====================================================================================================
==>step: 171, f_score: 0.42917299270629883, recall: 0.5873228311538696, precision:0.3782981038093567, sAP10: 0.48630908387005944
 
epo: 56, steps: 171 ,sAP10 : 0.4863 , best sAP10: 4.5000
{'fscore': 0.429173, 'recall': 0.58732283, 'precision': 0.3782981, 'sAP10': 0.48630908387005944}
====================================================================================================
==>step: 174, f_score: 0.47875165939331055, recall: 0.689390242099762, precision:0.3936387300491333, sAP10: 0.4987952379256727
 
epo: 57, steps: 174 ,sAP10 : 0.4988 , best sAP10: 4.5000
{'fscore': 0.47875166, 'recall': 0.68939024, 'precision': 0.39363873, 'sAP10': 0.4987952379256727}
====================================================================================================
==>step: 177, f_score: 0.45483073592185974, recall: 0.6941911578178406, precision:0.35972121357917786, sAP10: 0.2585150531312047
 
epo: 58, steps: 177 ,sAP10 : 0.2585 , best sAP10: 4.5000
{'fscore': 0.45483074, 'recall': 0.69419116, 'precision': 0.3597212, 'sAP10': 0.2585150531312047}
====================================================================================================
==>step: 180, f_score: 0.44731470942497253, recall: 0.74580979347229, precision:0.3346680998802185, sAP10: 0.2066365007541478
 
epo: 59, steps: 180 ,sAP10 : 0.2066 , best sAP10: 4.5000
{'fscore': 0.4473147, 'recall': 0.7458098, 'precision': 0.3346681, 'sAP10': 0.2066365007541478}
====================================================================================================
==>step: 183, f_score: 0.4449584186077118, recall: 0.6633282899856567, precision:0.3657286763191223, sAP10: 0.0
 
epo: 60, steps: 183 ,sAP10 : 0.0000 , best sAP10: 4.5000
{'fscore': 0.44495842, 'recall': 0.6633283, 'precision': 0.36572868, 'sAP10': 0.0}
====================================================================================================
==>step: 186, f_score: 0.4710769057273865, recall: 0.7134042978286743, precision:0.36800462007522583, sAP10: 0.018416206261510127
 
epo: 61, steps: 186 ,sAP10 : 0.0184 , best sAP10: 4.5000
{'fscore': 0.4710769, 'recall': 0.7134043, 'precision': 0.36800462, 'sAP10': 0.018416206261510127}
====================================================================================================
==>step: 189, f_score: 0.48169177770614624, recall: 0.7224122285842896, precision:0.37842366099357605, sAP10: 0.06076189014250262
 
epo: 62, steps: 189 ,sAP10 : 0.0608 , best sAP10: 4.5000
{'fscore': 0.48169178, 'recall': 0.7224122, 'precision': 0.37842366, 'sAP10': 0.06076189014250262}
====================================================================================================
==>step: 192, f_score: 0.49240148067474365, recall: 0.6623131036758423, precision:0.42721253633499146, sAP10: 0.36089983728762254
 
epo: 63, steps: 192 ,sAP10 : 0.3609 , best sAP10: 4.5000
{'fscore': 0.49240148, 'recall': 0.6623131, 'precision': 0.42721254, 'sAP10': 0.36089983728762254}
====================================================================================================
==>step: 195, f_score: 0.4757739007472992, recall: 0.7035972476005554, precision:0.37556612491607666, sAP10: 0.12578616352201258
 
epo: 64, steps: 195 ,sAP10 : 0.1258 , best sAP10: 4.5000
{'fscore': 0.4757739, 'recall': 0.70359725, 'precision': 0.37556612, 'sAP10': 0.12578616352201258}
====================================================================================================
==>step: 198, f_score: 0.4847329556941986, recall: 0.7226477861404419, precision:0.38246843218803406, sAP10: 0.7055974986654466
 
epo: 65, steps: 198 ,sAP10 : 0.7056 , best sAP10: 4.5000
{'fscore': 0.48473296, 'recall': 0.7226478, 'precision': 0.38246843, 'sAP10': 0.7055974986654466}
====================================================================================================
==>step: 201, f_score: 0.49471166729927063, recall: 0.6856001019477844, precision:0.40641897916793823, sAP10: 0.8122658999851982
 
epo: 66, steps: 201 ,sAP10 : 0.8123 , best sAP10: 4.5000
{'fscore': 0.49471167, 'recall': 0.6856001, 'precision': 0.40641898, 'sAP10': 0.8122658999851982}
====================================================================================================
==>step: 204, f_score: 0.5110315084457397, recall: 0.7731065154075623, precision:0.3987361490726471, sAP10: 0.2057156935205716
 
epo: 67, steps: 204 ,sAP10 : 0.2057 , best sAP10: 4.5000
{'fscore': 0.5110315, 'recall': 0.7731065, 'precision': 0.39873615, 'sAP10': 0.2057156935205716}
====================================================================================================
==>step: 207, f_score: 0.5194641947746277, recall: 0.8468224406242371, precision:0.3931218683719635, sAP10: 0.0808080808080808
 
epo: 68, steps: 207 ,sAP10 : 0.0808 , best sAP10: 4.5000
{'fscore': 0.5194642, 'recall': 0.84682244, 'precision': 0.39312187, 'sAP10': 0.0808080808080808}
====================================================================================================
==>step: 210, f_score: 0.47099292278289795, recall: 0.7207896709442139, precision:0.3693067133426666, sAP10: 1.3953369418186685
 
epo: 69, steps: 210 ,sAP10 : 1.3953 , best sAP10: 4.5000
{'fscore': 0.47099292, 'recall': 0.7207897, 'precision': 0.3693067, 'sAP10': 1.3953369418186685}
====================================================================================================
==>step: 213, f_score: 0.4762614369392395, recall: 0.719974935054779, precision:0.3736805021762848, sAP10: 1.3342075543756906
 
epo: 70, steps: 213 ,sAP10 : 1.3342 , best sAP10: 4.5000
{'fscore': 0.47626144, 'recall': 0.71997494, 'precision': 0.3736805, 'sAP10': 1.3342075543756906}
====================================================================================================
==>step: 216, f_score: 0.48233407735824585, recall: 0.7432075142860413, precision:0.3775620758533478, sAP10: 0.9597505601716957
 
epo: 71, steps: 216 ,sAP10 : 0.9598 , best sAP10: 4.5000
{'fscore': 0.48233408, 'recall': 0.7432075, 'precision': 0.37756208, 'sAP10': 0.9597505601716957}
====================================================================================================
==>step: 219, f_score: 0.4660210907459259, recall: 0.7166749238967896, precision:0.36604687571525574, sAP10: 0.03981507989524021
 
epo: 72, steps: 219 ,sAP10 : 0.0398 , best sAP10: 4.5000
{'fscore': 0.4660211, 'recall': 0.7166749, 'precision': 0.36604688, 'sAP10': 0.03981507989524021}
====================================================================================================
==>step: 222, f_score: 0.46389588713645935, recall: 0.7392646074295044, precision:0.35497310757637024, sAP10: 0.06116207951070337
 
epo: 73, steps: 222 ,sAP10 : 0.0612 , best sAP10: 4.5000
{'fscore': 0.4638959, 'recall': 0.7392646, 'precision': 0.3549731, 'sAP10': 0.06116207951070337}
====================================================================================================
==>step: 225, f_score: 0.5021231770515442, recall: 0.7902902364730835, precision:0.3847169280052185, sAP10: 0.1485148514851485
 
epo: 74, steps: 225 ,sAP10 : 0.1485 , best sAP10: 4.5000
{'fscore': 0.5021232, 'recall': 0.79029024, 'precision': 0.38471693, 'sAP10': 0.1485148514851485}
====================================================================================================
==>step: 228, f_score: 0.5172749161720276, recall: 0.7910299897193909, precision:0.40150678157806396, sAP10: 0.17543859649122812
 
epo: 75, steps: 228 ,sAP10 : 0.1754 , best sAP10: 4.5000
{'fscore': 0.5172749, 'recall': 0.79103, 'precision': 0.40150678, 'sAP10': 0.17543859649122812}
====================================================================================================
==>step: 231, f_score: 0.5210402607917786, recall: 0.8046872615814209, precision:0.40129101276397705, sAP10: 1.0761038478429783
 
epo: 76, steps: 231 ,sAP10 : 1.0761 , best sAP10: 4.5000
{'fscore': 0.52104026, 'recall': 0.80468726, 'precision': 0.401291, 'sAP10': 1.0761038478429783}
====================================================================================================
==>step: 234, f_score: 0.523003101348877, recall: 0.755580484867096, precision:0.4252544045448303, sAP10: 1.3970335161052954
 
epo: 77, steps: 234 ,sAP10 : 1.3970 , best sAP10: 4.5000
{'fscore': 0.5230031, 'recall': 0.7555805, 'precision': 0.4252544, 'sAP10': 1.3970335161052954}
====================================================================================================
==>step: 237, f_score: 0.5174667239189148, recall: 0.814038872718811, precision:0.399615615606308, sAP10: 0.7582361890467793
 
epo: 78, steps: 237 ,sAP10 : 0.7582 , best sAP10: 4.5000
{'fscore': 0.5174667, 'recall': 0.8140389, 'precision': 0.39961562, 'sAP10': 0.7582361890467793}
====================================================================================================
==>step: 240, f_score: 0.5027434229850769, recall: 0.7302399277687073, precision:0.40289273858070374, sAP10: 0.492503255331791
 
epo: 79, steps: 240 ,sAP10 : 0.4925 , best sAP10: 4.5000
{'fscore': 0.5027434, 'recall': 0.7302399, 'precision': 0.40289274, 'sAP10': 0.492503255331791}
====================================================================================================
==>step: 243, f_score: 0.5466868877410889, recall: 0.7939075231552124, precision:0.4462146759033203, sAP10: 0.8420832972689567
 
epo: 80, steps: 243 ,sAP10 : 0.8421 , best sAP10: 4.5000
{'fscore': 0.5466869, 'recall': 0.7939075, 'precision': 0.44621468, 'sAP10': 0.8420832972689567}
====================================================================================================
==>step: 246, f_score: 0.5689479112625122, recall: 0.7730872631072998, precision:0.48432493209838867, sAP10: 0.8680555555555556
 
epo: 81, steps: 246 ,sAP10 : 0.8681 , best sAP10: 4.5000
{'fscore': 0.5689479, 'recall': 0.77308726, 'precision': 0.48432493, 'sAP10': 0.8680555555555556}
====================================================================================================
==>step: 249, f_score: 0.5474586486816406, recall: 0.7628944516181946, precision:0.45402929186820984, sAP10: 1.864225372279496
 
epo: 82, steps: 249 ,sAP10 : 1.8642 , best sAP10: 4.5000
{'fscore': 0.54745865, 'recall': 0.76289445, 'precision': 0.4540293, 'sAP10': 1.864225372279496}
====================================================================================================
==>step: 252, f_score: 0.5303034782409668, recall: 0.7342710494995117, precision:0.4472750425338745, sAP10: 0.4669179229480737
 
epo: 83, steps: 252 ,sAP10 : 0.4669 , best sAP10: 4.5000
{'fscore': 0.5303035, 'recall': 0.73427105, 'precision': 0.44727504, 'sAP10': 0.4669179229480737}
====================================================================================================
==>step: 255, f_score: 0.5310420393943787, recall: 0.8145561814308167, precision:0.41097670793533325, sAP10: 1.1568084154854266
 
epo: 84, steps: 255 ,sAP10 : 1.1568 , best sAP10: 4.5000
{'fscore': 0.53104204, 'recall': 0.8145562, 'precision': 0.4109767, 'sAP10': 1.1568084154854266}
====================================================================================================
==>step: 258, f_score: 0.5282799601554871, recall: 0.8715675473213196, precision:0.38718318939208984, sAP10: 0.763250482351606
 
epo: 85, steps: 258 ,sAP10 : 0.7633 , best sAP10: 4.5000
{'fscore': 0.52827996, 'recall': 0.87156755, 'precision': 0.3871832, 'sAP10': 0.763250482351606}
====================================================================================================
==>step: 261, f_score: 0.5064051151275635, recall: 0.8660004138946533, precision:0.3659641146659851, sAP10: 0.01893939393939394
 
epo: 86, steps: 261 ,sAP10 : 0.0189 , best sAP10: 4.5000
{'fscore': 0.5064051, 'recall': 0.8660004, 'precision': 0.3659641, 'sAP10': 0.01893939393939394}
====================================================================================================
==>step: 264, f_score: 0.5129091739654541, recall: 0.8163110017776489, precision:0.39439713954925537, sAP10: 0.17497893864265252
 
epo: 87, steps: 264 ,sAP10 : 0.1750 , best sAP10: 4.5000
{'fscore': 0.5129092, 'recall': 0.816311, 'precision': 0.39439714, 'sAP10': 0.17497893864265252}
====================================================================================================
==>step: 267, f_score: 0.4905485212802887, recall: 0.776736319065094, precision:0.38157328963279724, sAP10: 0.1732340316103891
 
epo: 88, steps: 267 ,sAP10 : 0.1732 , best sAP10: 4.5000
{'fscore': 0.49054852, 'recall': 0.7767363, 'precision': 0.3815733, 'sAP10': 0.1732340316103891}
====================================================================================================
==>step: 270, f_score: 0.49490275979042053, recall: 0.7275754809379578, precision:0.4005272686481476, sAP10: 0.6914809938617971
 
epo: 89, steps: 270 ,sAP10 : 0.6915 , best sAP10: 4.5000
{'fscore': 0.49490276, 'recall': 0.7275755, 'precision': 0.40052727, 'sAP10': 0.6914809938617971}
====================================================================================================
==>step: 273, f_score: 0.4925544857978821, recall: 0.7746109366416931, precision:0.3811449706554413, sAP10: 1.7521367521367521
 
epo: 90, steps: 273 ,sAP10 : 1.7521 , best sAP10: 4.5000
{'fscore': 0.4925545, 'recall': 0.77461094, 'precision': 0.38114497, 'sAP10': 1.7521367521367521}
====================================================================================================
==>step: 276, f_score: 0.515412449836731, recall: 0.7346493005752563, precision:0.42230790853500366, sAP10: 0.6666666666666667
 
epo: 91, steps: 276 ,sAP10 : 0.6667 , best sAP10: 4.5000
{'fscore': 0.51541245, 'recall': 0.7346493, 'precision': 0.4223079, 'sAP10': 0.6666666666666667}
====================================================================================================
==>step: 279, f_score: 0.5376155972480774, recall: 0.7079557180404663, precision:0.4698565602302551, sAP10: 0.8215467830315073
 
epo: 92, steps: 279 ,sAP10 : 0.8215 , best sAP10: 4.5000
{'fscore': 0.5376156, 'recall': 0.7079557, 'precision': 0.46985656, 'sAP10': 0.8215467830315073}
====================================================================================================
==>step: 282, f_score: 0.5453884601593018, recall: 0.7779906988143921, precision:0.4470159709453583, sAP10: 0.1492537313432836
 
epo: 93, steps: 282 ,sAP10 : 0.1493 , best sAP10: 4.5000
{'fscore': 0.54538846, 'recall': 0.7779907, 'precision': 0.44701597, 'sAP10': 0.1492537313432836}
====================================================================================================
==>step: 285, f_score: 0.4325672388076782, recall: 0.5298614501953125, precision:0.41913357377052307, sAP10: 0.2519063180827887
 
epo: 94, steps: 285 ,sAP10 : 0.2519 , best sAP10: 4.5000
{'fscore': 0.43256724, 'recall': 0.52986145, 'precision': 0.41913357, 'sAP10': 0.2519063180827887}
====================================================================================================
==>step: 288, f_score: 0.5388185977935791, recall: 0.7629071474075317, precision:0.44585081934928894, sAP10: 0.46236559139784955
 
epo: 95, steps: 288 ,sAP10 : 0.4624 , best sAP10: 4.5000
{'fscore': 0.5388186, 'recall': 0.76290715, 'precision': 0.44585082, 'sAP10': 0.46236559139784955}
====================================================================================================
==>step: 291, f_score: 0.5849456787109375, recall: 0.785767138004303, precision:0.49395835399627686, sAP10: 1.3805734108764411
 
epo: 96, steps: 291 ,sAP10 : 1.3806 , best sAP10: 4.5000
{'fscore': 0.5849457, 'recall': 0.78576714, 'precision': 0.49395835, 'sAP10': 1.3805734108764411}
====================================================================================================
==>step: 294, f_score: 0.5799688100814819, recall: 0.7262687683105469, precision:0.5250890254974365, sAP10: 1.1601307189542482
 
epo: 97, steps: 294 ,sAP10 : 1.1601 , best sAP10: 4.5000
{'fscore': 0.5799688, 'recall': 0.72626877, 'precision': 0.525089, 'sAP10': 1.1601307189542482}
====================================================================================================
==>step: 297, f_score: 0.5381131768226624, recall: 0.8481094241142273, precision:0.4065074920654297, sAP10: 0.22975198106411446
 
epo: 98, steps: 297 ,sAP10 : 0.2298 , best sAP10: 4.5000
{'fscore': 0.5381132, 'recall': 0.8481094, 'precision': 0.4065075, 'sAP10': 0.22975198106411446}
====================================================================================================
==>step: 300, f_score: 0.6041844487190247, recall: 0.805957555770874, precision:0.5104708075523376, sAP10: 0.663983903420523
 
epo: 99, steps: 300 ,sAP10 : 0.6640 , best sAP10: 4.5000
{'fscore': 0.60418445, 'recall': 0.80595756, 'precision': 0.5104708, 'sAP10': 0.663983903420523}
====================================================================================================
==>step: 303, f_score: 0.6022356748580933, recall: 0.8199699521064758, precision:0.5027245283126831, sAP10: 0.6027890238416554
 
epo: 100, steps: 303 ,sAP10 : 0.6028 , best sAP10: 4.5000
{'fscore': 0.6022357, 'recall': 0.81996995, 'precision': 0.5027245, 'sAP10': 0.6027890238416554}
====================================================================================================
==>step: 306, f_score: 0.5925102829933167, recall: 0.8279048800468445, precision:0.48444220423698425, sAP10: 0.6924967495422825
 
epo: 101, steps: 306 ,sAP10 : 0.6925 , best sAP10: 4.5000
{'fscore': 0.5925103, 'recall': 0.8279049, 'precision': 0.4844422, 'sAP10': 0.6924967495422825}
====================================================================================================
==>step: 309, f_score: 0.5832855105400085, recall: 0.8430148363113403, precision:0.4687453508377075, sAP10: 0.727671325280887
 
epo: 102, steps: 309 ,sAP10 : 0.7277 , best sAP10: 4.5000
{'fscore': 0.5832855, 'recall': 0.84301484, 'precision': 0.46874535, 'sAP10': 0.727671325280887}
====================================================================================================
==>step: 312, f_score: 0.5675593614578247, recall: 0.8338788151741028, precision:0.45399361848831177, sAP10: 3.728166570271835
 
epo: 103, steps: 312 ,sAP10 : 3.7282 , best sAP10: 4.5000
{'fscore': 0.56755936, 'recall': 0.8338788, 'precision': 0.45399362, 'sAP10': 3.728166570271835}
====================================================================================================
==>step: 315, f_score: 0.5731187462806702, recall: 0.819256067276001, precision:0.46714478731155396, sAP10: 0.8559399506564456
 
epo: 104, steps: 315 ,sAP10 : 0.8559 , best sAP10: 4.5000
{'fscore': 0.57311875, 'recall': 0.81925607, 'precision': 0.4671448, 'sAP10': 0.8559399506564456}
====================================================================================================
==>step: 318, f_score: 0.5647361278533936, recall: 0.8257057070732117, precision:0.45685645937919617, sAP10: 1.5380705569453301
 
epo: 105, steps: 318 ,sAP10 : 1.5381 , best sAP10: 4.5000
{'fscore': 0.5647361, 'recall': 0.8257057, 'precision': 0.45685646, 'sAP10': 1.5380705569453301}
====================================================================================================
==>step: 321, f_score: 0.5563080906867981, recall: 0.8397742509841919, precision:0.43541452288627625, sAP10: 0.7533455683653135
 
epo: 106, steps: 321 ,sAP10 : 0.7533 , best sAP10: 4.5000
{'fscore': 0.5563081, 'recall': 0.83977425, 'precision': 0.43541452, 'sAP10': 0.7533455683653135}
====================================================================================================
==>step: 324, f_score: 0.5570029020309448, recall: 0.8471544981002808, precision:0.43529826402664185, sAP10: 0.9878519169299309
 
epo: 107, steps: 324 ,sAP10 : 0.9879 , best sAP10: 4.5000
{'fscore': 0.5570029, 'recall': 0.8471545, 'precision': 0.43529826, 'sAP10': 0.9878519169299309}
====================================================================================================
==>step: 327, f_score: 0.5569456219673157, recall: 0.845903754234314, precision:0.435447633266449, sAP10: 1.0288329819863975
 
epo: 108, steps: 327 ,sAP10 : 1.0288 , best sAP10: 4.5000
{'fscore': 0.5569456, 'recall': 0.84590375, 'precision': 0.43544763, 'sAP10': 1.0288329819863975}
====================================================================================================
==>step: 330, f_score: 0.560499370098114, recall: 0.838745653629303, precision:0.4435492157936096, sAP10: 1.8365252954006008
 
epo: 109, steps: 330 ,sAP10 : 1.8365 , best sAP10: 4.5000
{'fscore': 0.56049937, 'recall': 0.83874565, 'precision': 0.44354922, 'sAP10': 1.8365252954006008}
====================================================================================================
==>step: 333, f_score: 0.5616509914398193, recall: 0.8366037607192993, precision:0.44645068049430847, sAP10: 0.9887400071128651
 
epo: 110, steps: 333 ,sAP10 : 0.9887 , best sAP10: 4.5000
{'fscore': 0.561651, 'recall': 0.83660376, 'precision': 0.44645068, 'sAP10': 0.9887400071128651}
====================================================================================================
==>step: 336, f_score: 0.5674946904182434, recall: 0.8219203948974609, precision:0.46069973707199097, sAP10: 1.907097050377629
 
epo: 111, steps: 336 ,sAP10 : 1.9071 , best sAP10: 4.5000
{'fscore': 0.5674947, 'recall': 0.8219204, 'precision': 0.46069974, 'sAP10': 1.907097050377629}
====================================================================================================
==>step: 339, f_score: 0.5694958567619324, recall: 0.815021812915802, precision:0.4664330780506134, sAP10: 2.206874056332666
 
epo: 112, steps: 339 ,sAP10 : 2.2069 , best sAP10: 4.5000
{'fscore': 0.56949586, 'recall': 0.8150218, 'precision': 0.46643308, 'sAP10': 2.206874056332666}
====================================================================================================
==>step: 342, f_score: 0.5646095871925354, recall: 0.8202059268951416, precision:0.4594016671180725, sAP10: 4.59763236914303
 
epo: 113, steps: 342 ,sAP10 : 4.5976 , best sAP10: 4.5976
{'fscore': 0.5646096, 'recall': 0.8202059, 'precision': 0.45940167, 'sAP10': 4.59763236914303}
====================================================================================================
==>step: 345, f_score: 0.5538858771324158, recall: 0.8206973671913147, precision:0.44282016158103943, sAP10: 2.9125872274811155
 
epo: 114, steps: 345 ,sAP10 : 2.9126 , best sAP10: 4.5976
{'fscore': 0.5538859, 'recall': 0.82069737, 'precision': 0.44282016, 'sAP10': 2.9125872274811155}
====================================================================================================
==>step: 348, f_score: 0.5483506321907043, recall: 0.8204658627510071, precision:0.43551117181777954, sAP10: 2.0779658937553673
 
epo: 115, steps: 348 ,sAP10 : 2.0780 , best sAP10: 4.5976
{'fscore': 0.54835063, 'recall': 0.82046586, 'precision': 0.43551117, 'sAP10': 2.0779658937553673}
====================================================================================================
==>step: 351, f_score: 0.5504955053329468, recall: 0.8195655941963196, precision:0.4377642571926117, sAP10: 2.079248366013072
 
epo: 116, steps: 351 ,sAP10 : 2.0792 , best sAP10: 4.5976
{'fscore': 0.5504955, 'recall': 0.8195656, 'precision': 0.43776426, 'sAP10': 2.079248366013072}
====================================================================================================
==>step: 354, f_score: 0.5645948052406311, recall: 0.8154264092445374, precision:0.45690929889678955, sAP10: 1.238256024444416
 
epo: 117, steps: 354 ,sAP10 : 1.2383 , best sAP10: 4.5976
{'fscore': 0.5645948, 'recall': 0.8154264, 'precision': 0.4569093, 'sAP10': 1.238256024444416}
====================================================================================================
==>step: 357, f_score: 0.5553725957870483, recall: 0.7953169941902161, precision:0.4513685405254364, sAP10: 1.1910294132516355
 
epo: 118, steps: 357 ,sAP10 : 1.1910 , best sAP10: 4.5976
{'fscore': 0.5553726, 'recall': 0.795317, 'precision': 0.45136854, 'sAP10': 1.1910294132516355}
====================================================================================================
==>step: 360, f_score: 0.5732768177986145, recall: 0.8169211149215698, precision:0.46989306807518005, sAP10: 1.8862701065263079
 
epo: 119, steps: 360 ,sAP10 : 1.8863 , best sAP10: 4.5976
{'fscore': 0.5732768, 'recall': 0.8169211, 'precision': 0.46989307, 'sAP10': 1.8862701065263079}
====================================================================================================
==>step: 363, f_score: 0.5767889022827148, recall: 0.8264120817184448, precision:0.4714488685131073, sAP10: 2.8562458057712585
 
epo: 120, steps: 363 ,sAP10 : 2.8562 , best sAP10: 4.5976
{'fscore': 0.5767889, 'recall': 0.8264121, 'precision': 0.47144887, 'sAP10': 2.8562458057712585}
====================================================================================================
==>step: 366, f_score: 0.5675098896026611, recall: 0.8312022089958191, precision:0.45601335167884827, sAP10: 2.33958899704756
 
epo: 121, steps: 366 ,sAP10 : 2.3396 , best sAP10: 4.5976
{'fscore': 0.5675099, 'recall': 0.8312022, 'precision': 0.45601335, 'sAP10': 2.33958899704756}
====================================================================================================
==>step: 369, f_score: 0.5671743154525757, recall: 0.826168954372406, precision:0.45696502923965454, sAP10: 0.7808247253648138
 
epo: 122, steps: 369 ,sAP10 : 0.7808 , best sAP10: 4.5976
{'fscore': 0.5671743, 'recall': 0.82616895, 'precision': 0.45696503, 'sAP10': 0.7808247253648138}
====================================================================================================
==>step: 372, f_score: 0.5672963857650757, recall: 0.814065158367157, precision:0.458818256855011, sAP10: 2.105298801656722
 
epo: 123, steps: 372 ,sAP10 : 2.1053 , best sAP10: 4.5976
{'fscore': 0.5672964, 'recall': 0.81406516, 'precision': 0.45881826, 'sAP10': 2.105298801656722}
====================================================================================================
==>step: 375, f_score: 0.5749642848968506, recall: 0.8102590441703796, precision:0.47326594591140747, sAP10: 1.8253036082493446
 
epo: 124, steps: 375 ,sAP10 : 1.8253 , best sAP10: 4.5976
{'fscore': 0.5749643, 'recall': 0.81025904, 'precision': 0.47326595, 'sAP10': 1.8253036082493446}
====================================================================================================
==>step: 378, f_score: 0.5770435929298401, recall: 0.8095605373382568, precision:0.4741075932979584, sAP10: 1.221026592455164
 
epo: 125, steps: 378 ,sAP10 : 1.2210 , best sAP10: 4.5976
{'fscore': 0.5770436, 'recall': 0.80956054, 'precision': 0.4741076, 'sAP10': 1.221026592455164}
====================================================================================================
==>step: 381, f_score: 0.578175961971283, recall: 0.8126930594444275, precision:0.4756574034690857, sAP10: 1.7603914558385436
 
epo: 126, steps: 381 ,sAP10 : 1.7604 , best sAP10: 4.5976
{'fscore': 0.57817596, 'recall': 0.81269306, 'precision': 0.4756574, 'sAP10': 1.7603914558385436}
====================================================================================================
==>step: 384, f_score: 0.5876981019973755, recall: 0.8076928853988647, precision:0.4947231411933899, sAP10: 1.7510163142139619
 
epo: 127, steps: 384 ,sAP10 : 1.7510 , best sAP10: 4.5976
{'fscore': 0.5876981, 'recall': 0.8076929, 'precision': 0.49472314, 'sAP10': 1.7510163142139619}
====================================================================================================
==>step: 387, f_score: 0.5746168494224548, recall: 0.7723544836044312, precision:0.4953398108482361, sAP10: 2.024031285150367
 
epo: 128, steps: 387 ,sAP10 : 2.0240 , best sAP10: 4.5976
{'fscore': 0.57461685, 'recall': 0.7723545, 'precision': 0.4953398, 'sAP10': 2.024031285150367}
====================================================================================================
==>step: 390, f_score: 0.5863248109817505, recall: 0.8051502704620361, precision:0.49314695596694946, sAP10: 1.6260614681667311
 
epo: 129, steps: 390 ,sAP10 : 1.6261 , best sAP10: 4.5976
{'fscore': 0.5863248, 'recall': 0.8051503, 'precision': 0.49314696, 'sAP10': 1.6260614681667311}
====================================================================================================
==>step: 393, f_score: 0.565594494342804, recall: 0.8259267807006836, precision:0.45573678612709045, sAP10: 1.6774966672561313
 
epo: 130, steps: 393 ,sAP10 : 1.6775 , best sAP10: 4.5976
{'fscore': 0.5655945, 'recall': 0.8259268, 'precision': 0.4557368, 'sAP10': 1.6774966672561313}
====================================================================================================
==>step: 396, f_score: 0.5550585389137268, recall: 0.8296447992324829, precision:0.43940725922584534, sAP10: 2.124653644853419
 
epo: 131, steps: 396 ,sAP10 : 2.1247 , best sAP10: 4.5976
{'fscore': 0.55505854, 'recall': 0.8296448, 'precision': 0.43940726, 'sAP10': 2.124653644853419}
====================================================================================================
==>step: 399, f_score: 0.563029944896698, recall: 0.831036388874054, precision:0.44813621044158936, sAP10: 1.63075915611218
 
epo: 132, steps: 399 ,sAP10 : 1.6308 , best sAP10: 4.5976
{'fscore': 0.56302994, 'recall': 0.8310364, 'precision': 0.4481362, 'sAP10': 1.63075915611218}
====================================================================================================
==>step: 402, f_score: 0.5531463623046875, recall: 0.8100273609161377, precision:0.4464392066001892, sAP10: 0.7074877566436653
 
epo: 133, steps: 402 ,sAP10 : 0.7075 , best sAP10: 4.5976
{'fscore': 0.55314636, 'recall': 0.81002736, 'precision': 0.4464392, 'sAP10': 0.7074877566436653}
====================================================================================================
==>step: 405, f_score: 0.5282593965530396, recall: 0.7733598351478577, precision:0.42689597606658936, sAP10: 0.740041427222228
 
epo: 134, steps: 405 ,sAP10 : 0.7400 , best sAP10: 4.5976
{'fscore': 0.5282594, 'recall': 0.77335984, 'precision': 0.42689598, 'sAP10': 0.740041427222228}
====================================================================================================
==>step: 408, f_score: 0.5273400545120239, recall: 0.7742983102798462, precision:0.4265940487384796, sAP10: 0.740493991659881
 
epo: 135, steps: 408 ,sAP10 : 0.7405 , best sAP10: 4.5976
{'fscore': 0.52734005, 'recall': 0.7742983, 'precision': 0.42659405, 'sAP10': 0.740493991659881}
====================================================================================================
==>step: 411, f_score: 0.549296498298645, recall: 0.8204692006111145, precision:0.4337862432003021, sAP10: 0.8959915745216835
 
epo: 136, steps: 411 ,sAP10 : 0.8960 , best sAP10: 4.5976
{'fscore': 0.5492965, 'recall': 0.8204692, 'precision': 0.43378624, 'sAP10': 0.8959915745216835}
====================================================================================================
==>step: 414, f_score: 0.5454273223876953, recall: 0.8356414437294006, precision:0.42456018924713135, sAP10: 0.7317637820901762
 
epo: 137, steps: 414 ,sAP10 : 0.7318 , best sAP10: 4.5976
{'fscore': 0.5454273, 'recall': 0.83564144, 'precision': 0.4245602, 'sAP10': 0.7317637820901762}
====================================================================================================
==>step: 417, f_score: 0.5429229140281677, recall: 0.8330724239349365, precision:0.42166364192962646, sAP10: 0.7675554543626679
 
epo: 138, steps: 417 ,sAP10 : 0.7676 , best sAP10: 4.5976
{'fscore': 0.5429229, 'recall': 0.8330724, 'precision': 0.42166364, 'sAP10': 0.7675554543626679}
====================================================================================================
==>step: 420, f_score: 0.5515773892402649, recall: 0.8171290159225464, precision:0.4367832839488983, sAP10: 0.6695490302047677
 
epo: 139, steps: 420 ,sAP10 : 0.6695 , best sAP10: 4.5976
{'fscore': 0.5515774, 'recall': 0.817129, 'precision': 0.43678328, 'sAP10': 0.6695490302047677}
====================================================================================================
==>step: 423, f_score: 0.5566008687019348, recall: 0.8184543251991272, precision:0.4421505630016327, sAP10: 1.2894239943420271
 
epo: 140, steps: 423 ,sAP10 : 1.2894 , best sAP10: 4.5976
{'fscore': 0.55660087, 'recall': 0.8184543, 'precision': 0.44215056, 'sAP10': 1.2894239943420271}
====================================================================================================
==>step: 426, f_score: 0.5474219918251038, recall: 0.8147367835044861, precision:0.4318296015262604, sAP10: 1.4466159019500922
 
epo: 141, steps: 426 ,sAP10 : 1.4466 , best sAP10: 4.5976
{'fscore': 0.547422, 'recall': 0.8147368, 'precision': 0.4318296, 'sAP10': 1.4466159019500922}
====================================================================================================
==>step: 429, f_score: 0.5555524826049805, recall: 0.8246784210205078, precision:0.4389720857143402, sAP10: 1.2585890466069263
 
epo: 142, steps: 429 ,sAP10 : 1.2586 , best sAP10: 4.5976
{'fscore': 0.5555525, 'recall': 0.8246784, 'precision': 0.4389721, 'sAP10': 1.2585890466069263}
====================================================================================================
==>step: 432, f_score: 0.5621563792228699, recall: 0.8207833766937256, precision:0.44793298840522766, sAP10: 1.1571936964202156
 
epo: 143, steps: 432 ,sAP10 : 1.1572 , best sAP10: 4.5976
{'fscore': 0.5621564, 'recall': 0.8207834, 'precision': 0.447933, 'sAP10': 1.1571936964202156}
====================================================================================================
==>step: 435, f_score: 0.5616549253463745, recall: 0.7974087595939636, precision:0.4602659046649933, sAP10: 0.9832172658259616
 
epo: 144, steps: 435 ,sAP10 : 0.9832 , best sAP10: 4.5976
{'fscore': 0.5616549, 'recall': 0.79740876, 'precision': 0.4602659, 'sAP10': 0.9832172658259616}
====================================================================================================
==>step: 438, f_score: 0.5660329461097717, recall: 0.8155080080032349, precision:0.45402660965919495, sAP10: 1.1541768334098526
 
epo: 145, steps: 438 ,sAP10 : 1.1542 , best sAP10: 4.5976
{'fscore': 0.56603295, 'recall': 0.815508, 'precision': 0.4540266, 'sAP10': 1.1541768334098526}
====================================================================================================
==>step: 441, f_score: 0.5748779773712158, recall: 0.8227404356002808, precision:0.46151435375213623, sAP10: 2.06845594696062
 
epo: 146, steps: 441 ,sAP10 : 2.0685 , best sAP10: 4.5976
{'fscore': 0.574878, 'recall': 0.82274044, 'precision': 0.46151435, 'sAP10': 2.06845594696062}
====================================================================================================
==>step: 444, f_score: 0.5750167965888977, recall: 0.8179420232772827, precision:0.4659503400325775, sAP10: 2.236029526029526
 
epo: 147, steps: 444 ,sAP10 : 2.2360 , best sAP10: 4.5976
{'fscore': 0.5750168, 'recall': 0.817942, 'precision': 0.46595034, 'sAP10': 2.236029526029526}
====================================================================================================
==>step: 447, f_score: 0.5769392848014832, recall: 0.8092048764228821, precision:0.4750506579875946, sAP10: 2.40102423689281
 
epo: 148, steps: 447 ,sAP10 : 2.4010 , best sAP10: 4.5976
{'fscore': 0.5769393, 'recall': 0.8092049, 'precision': 0.47505066, 'sAP10': 2.40102423689281}
====================================================================================================
==>step: 450, f_score: 0.5509827733039856, recall: 0.7697909474372864, precision:0.4586579203605652, sAP10: 1.867551923731699
 
epo: 149, steps: 450 ,sAP10 : 1.8676 , best sAP10: 4.5976
{'fscore': 0.5509828, 'recall': 0.76979095, 'precision': 0.45865792, 'sAP10': 1.867551923731699}
====================================================================================================
==>step: 453, f_score: 0.5453435182571411, recall: 0.7692146301269531, precision:0.4506693482398987, sAP10: 2.1087631058729324
 
epo: 150, steps: 453 ,sAP10 : 2.1088 , best sAP10: 4.5976
{'fscore': 0.5453435, 'recall': 0.76921463, 'precision': 0.45066935, 'sAP10': 2.1087631058729324}
====================================================================================================
==>step: 456, f_score: 0.5632085204124451, recall: 0.7947285771369934, precision:0.4600142240524292, sAP10: 2.055836284693923
 
epo: 151, steps: 456 ,sAP10 : 2.0558 , best sAP10: 4.5976
{'fscore': 0.5632085, 'recall': 0.7947286, 'precision': 0.46001422, 'sAP10': 2.055836284693923}
====================================================================================================
==>step: 459, f_score: 0.5684335827827454, recall: 0.7993853092193604, precision:0.46468886733055115, sAP10: 2.43685630721659
 
epo: 152, steps: 459 ,sAP10 : 2.4369 , best sAP10: 4.5976
{'fscore': 0.5684336, 'recall': 0.7993853, 'precision': 0.46468887, 'sAP10': 2.43685630721659}
====================================================================================================
==>step: 462, f_score: 0.5749637484550476, recall: 0.8048047423362732, precision:0.47094568610191345, sAP10: 2.4627871723549237
 
epo: 153, steps: 462 ,sAP10 : 2.4628 , best sAP10: 4.5976
{'fscore': 0.57496375, 'recall': 0.80480474, 'precision': 0.4709457, 'sAP10': 2.4627871723549237}
====================================================================================================
==>step: 465, f_score: 0.5788925886154175, recall: 0.8024482727050781, precision:0.4770321846008301, sAP10: 2.612200435729848
 
epo: 154, steps: 465 ,sAP10 : 2.6122 , best sAP10: 4.5976
{'fscore': 0.5788926, 'recall': 0.8024483, 'precision': 0.47703218, 'sAP10': 2.612200435729848}
====================================================================================================
