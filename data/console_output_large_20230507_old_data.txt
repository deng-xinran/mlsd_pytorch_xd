using config:  mlsd_pytorch/configs/mobilev2_mlsd_large_512_base2_bsize24.yaml
datasets:
  input_size: 512
  name: wireframe
  with_centermap_extend: False
decode:
  len_thresh: 5
  score_thresh: 0.05
  top_k: 500
loss:
  focal_loss_level: 0
  loss_type: 1*L1
  loss_weight_dict_list: [{'tp_center_loss': 10.0, 'sol_center_loss': 1.0, 'tp_match_loss': 1.0}]
  match_sap_thresh: 5.0
  with_focal_loss: True
  with_match_loss: False
  with_sol_loss: True
model:
  model_name: mobilev2_mlsd_large
  num_classes: 1
  with_deconv: True
sys:
  cpu: False
  gpus: 1
  num_workers: 8
train:
  adam_epsilon: 1e-06
  batch_size: 24
  cache_to_mem: False
  data_cache_dir: ./data/wireframe_cache/
  device_ids: [0]
  device_ids_str: 0
  do_train: True
  dropout: 0.1
  early_stop_n: 200
  gradient_accumulation_steps: 1
  img_dir: ./data/wireframe_raw/images/
  label_fn: ./data/wireframe_raw/train_0.json
  learning_rate: 0.003
  load_from: 
  log_steps: 50
  lr_decay_gamma: 0.2
  milestones: [50, 100, 150]
  milestones_in_epo: True
  num_train_epochs: 155
  num_workers: 8
  save_dir: ./workdir/models/mobilev2_mlsd_large_512_bsize242023-08-08T12:41:06.233681/
  use_step_lr_policy: True
  warmup_steps: 100
  weight_decay: 1e-06
  with_cache: False
val:
  batch_size: 8
  img_dir: ./data/wireframe_raw/images/
  label_fn: ./data/wireframe_raw/valid.json
  val_after_epoch: 50
==> load label..
==> valid samples:  38
==> load label..
==> valid samples:  27
MobileV2_MLSD_Large(
  (backbone): MobileNetV2(
    (features): Sequential(
      (0): ConvBNReLU(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (block15): BlockTypeA(
    (conv1): Sequential(
      (0): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (block16): BlockTypeB(
    (conv1): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (block17): BlockTypeA(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (block18): BlockTypeB(
    (conv1): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (block19): BlockTypeA(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(24, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (block20): BlockTypeB(
    (conv1): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (block21): BlockTypeA(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (block22): BlockTypeB(
    (conv1): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (block23): BlockTypeC(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(5, 5), dilation=(5, 5))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv3): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
  )
)
===> loss weight:  {'tp_center_loss': 10.0, 'tp_displacement_loss': 1.0, 'tp_len_loss': 1.0, 'tp_angle_loss': 1.0, 'tp_match_loss': 1.0, 'tp_centerness_loss': 1.0, 'sol_center_loss': 1.0, 'sol_displacement_loss': 1.0, 'sol_len_loss': 1.0, 'sol_angle_loss': 1.0, 'sol_match_loss': 1.0, 'sol_centerness_loss': 1.0, 'line_seg_loss': 1.0, 'junc_seg_loss': 1.0}
==>step: 52, f_score: 0.006426898296922445, recall: 0.005039379000663757, precision:0.008933971635997295, sAP10: 0.0
 
epo: 51, steps: 52 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0064268983, 'recall': 0.005039379, 'precision': 0.008933972, 'sAP10': 0.0}
====================================================================================================
==>step: 53, f_score: 0.006020165514200926, recall: 0.004305488895624876, precision:0.010090554133057594, sAP10: 0.0
 
epo: 52, steps: 53 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0060201655, 'recall': 0.004305489, 'precision': 0.010090554, 'sAP10': 0.0}
====================================================================================================
==>step: 54, f_score: 0.00365300290286541, recall: 0.0023973744828253984, precision:0.007788870949298143, sAP10: 0.0
 
epo: 53, steps: 54 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.003653003, 'recall': 0.0023973745, 'precision': 0.007788871, 'sAP10': 0.0}
====================================================================================================
==>step: 55, f_score: 0.0012383878929540515, recall: 0.0007828161469660699, precision:0.0031025628559291363, sAP10: 0.0
 
epo: 54, steps: 55 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0012383879, 'recall': 0.00078281615, 'precision': 0.0031025629, 'sAP10': 0.0}
====================================================================================================
==>step: 56, f_score: 0.003218710655346513, recall: 0.002201670315116644, precision:0.006082702893763781, sAP10: 0.0
 
epo: 55, steps: 56 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0032187107, 'recall': 0.0022016703, 'precision': 0.006082703, 'sAP10': 0.0}
====================================================================================================
==>step: 57, f_score: 0.0030887762550264597, recall: 0.002348448382690549, precision:0.004581889603286982, sAP10: 0.0
 
epo: 56, steps: 57 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0030887763, 'recall': 0.0023484484, 'precision': 0.0045818896, 'sAP10': 0.0}
====================================================================================================
==>step: 58, f_score: 0.00531512126326561, recall: 0.004452266730368137, precision:0.00664766039699316, sAP10: 0.0
 
epo: 57, steps: 58 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0053151213, 'recall': 0.0044522667, 'precision': 0.0066476604, 'sAP10': 0.0}
====================================================================================================
==>step: 59, f_score: 0.0027849311009049416, recall: 0.0028866345528513193, precision:0.002724666381254792, sAP10: 0.0
 
epo: 58, steps: 59 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.002784931, 'recall': 0.0028866346, 'precision': 0.0027246664, 'sAP10': 0.0}
====================================================================================================
==>step: 60, f_score: 0.002161037642508745, recall: 0.0018102623289451003, precision:0.0027352648321539164, sAP10: 0.0
 
epo: 59, steps: 60 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0021610376, 'recall': 0.0018102623, 'precision': 0.0027352648, 'sAP10': 0.0}
====================================================================================================
==>step: 61, f_score: 0.0038213639054447412, recall: 0.0038651544600725174, precision:0.0038147615268826485, sAP10: 0.0
 
epo: 60, steps: 61 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.003821364, 'recall': 0.0038651545, 'precision': 0.0038147615, 'sAP10': 0.0}
====================================================================================================
==>step: 62, f_score: 0.0052191708236932755, recall: 0.004403340630233288, precision:0.006459936033934355, sAP10: 0.0
 
epo: 61, steps: 62 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.005219171, 'recall': 0.0044033406, 'precision': 0.006459936, 'sAP10': 0.0}
====================================================================================================
==>step: 63, f_score: 0.0012146009830757976, recall: 0.0008806681726127863, precision:0.0020387296099215746, sAP10: 0.0
 
epo: 62, steps: 63 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.001214601, 'recall': 0.0008806682, 'precision': 0.0020387296, 'sAP10': 0.0}
====================================================================================================
==>step: 64, f_score: 0.0005600937292911112, recall: 0.00039140807348303497, precision:0.0010774371912702918, sAP10: 0.0
 
epo: 63, steps: 64 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.00056009373, 'recall': 0.00039140807, 'precision': 0.0010774372, 'sAP10': 0.0}
====================================================================================================
==>step: 65, f_score: 0.00071601482341066, recall: 0.0004892600700259209, precision:0.0014355385210365057, sAP10: 0.0
 
epo: 64, steps: 65 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0007160148, 'recall': 0.00048926007, 'precision': 0.0014355385, 'sAP10': 0.0}
====================================================================================================
==>step: 66, f_score: 0.0014197933487594128, recall: 0.0009785201400518417, precision:0.002683833474293351, sAP10: 0.0
 
epo: 65, steps: 66 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0014197933, 'recall': 0.0009785201, 'precision': 0.0026838335, 'sAP10': 0.0}
====================================================================================================
==>step: 67, f_score: 0.0013667752500623465, recall: 0.0009785201400518417, precision:0.0023515503853559494, sAP10: 0.0
 
epo: 66, steps: 67 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0013667753, 'recall': 0.0009785201, 'precision': 0.0023515504, 'sAP10': 0.0}
====================================================================================================
==>step: 68, f_score: 0.003117641434073448, recall: 0.0022995222825556993, precision:0.004917332902550697, sAP10: 0.0
 
epo: 67, steps: 68 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0031176414, 'recall': 0.0022995223, 'precision': 0.004917333, 'sAP10': 0.0}
====================================================================================================
==>step: 69, f_score: 0.002300780965015292, recall: 0.001712410245090723, precision:0.003580919001251459, sAP10: 0.0
 
epo: 68, steps: 69 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.002300781, 'recall': 0.0017124102, 'precision': 0.003580919, 'sAP10': 0.0}
====================================================================================================
==>step: 70, f_score: 0.0014155703829601407, recall: 0.0012231501750648022, precision:0.0017306993249803782, sAP10: 0.0
 
epo: 69, steps: 70 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0014155704, 'recall': 0.0012231502, 'precision': 0.0017306993, 'sAP10': 0.0}
====================================================================================================
==>step: 71, f_score: 0.001573934918269515, recall: 0.0013699281262233853, precision:0.00189933180809021, sAP10: 0.0
 
epo: 70, steps: 71 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0015739349, 'recall': 0.0013699281, 'precision': 0.0018993318, 'sAP10': 0.0}
====================================================================================================
==>step: 72, f_score: 0.0015684642130509019, recall: 0.0013210021425038576, precision:0.001984122907742858, sAP10: 0.0
 
epo: 71, steps: 72 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0015684642, 'recall': 0.0013210021, 'precision': 0.001984123, 'sAP10': 0.0}
====================================================================================================
==>step: 73, f_score: 0.0026726124342530966, recall: 0.0022995222825556993, precision:0.0032415969762951136, sAP10: 0.0
 
epo: 72, steps: 73 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0026726124, 'recall': 0.0022995223, 'precision': 0.003241597, 'sAP10': 0.0}
====================================================================================================
==>step: 74, f_score: 0.003138628788292408, recall: 0.002348448382690549, precision:0.004804791882634163, sAP10: 0.0
 
epo: 73, steps: 74 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0031386288, 'recall': 0.0023484484, 'precision': 0.004804792, 'sAP10': 0.0}
====================================================================================================
==>step: 75, f_score: 0.0022976610343903303, recall: 0.0016145581612363458, precision:0.00407406035810709, sAP10: 0.0
 
epo: 74, steps: 75 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.002297661, 'recall': 0.0016145582, 'precision': 0.0040740604, 'sAP10': 0.0}
====================================================================================================
==>step: 76, f_score: 0.002063584513962269, recall: 0.0014677802100777626, precision:0.0035612420178949833, sAP10: 0.0
 
epo: 75, steps: 76 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0020635845, 'recall': 0.0014677802, 'precision': 0.003561242, 'sAP10': 0.0}
====================================================================================================
==>step: 77, f_score: 0.002476970897987485, recall: 0.0017613363452255726, precision:0.0042598373256623745, sAP10: 0.0
 
epo: 76, steps: 77 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.002476971, 'recall': 0.0017613363, 'precision': 0.0042598373, 'sAP10': 0.0}
====================================================================================================
==>step: 78, f_score: 0.002089140936732292, recall: 0.0015167063102126122, precision:0.0034375591203570366, sAP10: 0.0
 
epo: 77, steps: 78 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.002089141, 'recall': 0.0015167063, 'precision': 0.0034375591, 'sAP10': 0.0}
====================================================================================================
==>step: 79, f_score: 0.003723488887771964, recall: 0.00278878235258162, precision:0.005675014574080706, sAP10: 0.0
 
epo: 78, steps: 79 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.003723489, 'recall': 0.0027887824, 'precision': 0.0056750146, 'sAP10': 0.0}
====================================================================================================
==>step: 80, f_score: 0.005740455351769924, recall: 0.004696896765381098, precision:0.007438385393470526, sAP10: 0.0
 
epo: 79, steps: 80 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0057404554, 'recall': 0.0046968968, 'precision': 0.0074383854, 'sAP10': 0.0}
====================================================================================================
==>step: 81, f_score: 0.004352704621851444, recall: 0.004550118464976549, precision:0.004205665551126003, sAP10: 0.0
 
epo: 80, steps: 81 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0043527046, 'recall': 0.0045501185, 'precision': 0.0042056656, 'sAP10': 0.0}
====================================================================================================
==>step: 82, f_score: 0.005006210878491402, recall: 0.004745822865515947, precision:0.005338168237358332, sAP10: 0.0
 
epo: 81, steps: 82 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.005006211, 'recall': 0.004745823, 'precision': 0.0053381682, 'sAP10': 0.0}
====================================================================================================
==>step: 83, f_score: 0.008568680845201015, recall: 0.0073389015160501, precision:0.010345522314310074, sAP10: 0.0
 
epo: 82, steps: 83 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.008568681, 'recall': 0.0073389015, 'precision': 0.010345522, 'sAP10': 0.0}
====================================================================================================
==>step: 84, f_score: 0.006101411301642656, recall: 0.00366945075802505, precision:0.018274733796715736, sAP10: 0.0
 
epo: 83, steps: 84 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0061014113, 'recall': 0.0036694508, 'precision': 0.018274734, 'sAP10': 0.0}
====================================================================================================
==>step: 85, f_score: 0.004674788564443588, recall: 0.0025441525503993034, precision:0.0291802529245615, sAP10: 0.0
 
epo: 84, steps: 85 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0046747886, 'recall': 0.0025441526, 'precision': 0.029180253, 'sAP10': 0.0}
====================================================================================================
==>step: 86, f_score: 0.0, recall: 0.0, precision:0.0, sAP10: 0.0
 
epo: 85, steps: 86 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0, 'recall': 0.0, 'precision': 0.0, 'sAP10': 0.0}
====================================================================================================
==>step: 87, f_score: 0.0, recall: 0.0, precision:0.0, sAP10: 0.0
 
epo: 86, steps: 87 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0, 'recall': 0.0, 'precision': 0.0, 'sAP10': 0.0}
====================================================================================================
==>step: 88, f_score: 0.0, recall: 0.0, precision:0.0, sAP10: 0.0
 
epo: 87, steps: 88 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0, 'recall': 0.0, 'precision': 0.0, 'sAP10': 0.0}
====================================================================================================
==>step: 89, f_score: 0.0, recall: 0.0, precision:0.0, sAP10: 0.0
 
epo: 88, steps: 89 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0, 'recall': 0.0, 'precision': 0.0, 'sAP10': 0.0}
====================================================================================================
==>step: 90, f_score: 0.0, recall: 0.0, precision:0.0, sAP10: 0.0
 
epo: 89, steps: 90 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0, 'recall': 0.0, 'precision': 0.0, 'sAP10': 0.0}
====================================================================================================
==>step: 91, f_score: 0.0, recall: 0.0, precision:0.0, sAP10: 0.0
 
epo: 90, steps: 91 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.0, 'recall': 0.0, 'precision': 0.0, 'sAP10': 0.0}
====================================================================================================
==>step: 92, f_score: 0.03811891749501228, recall: 0.021473897621035576, precision:0.21382306516170502, sAP10: 0.0
 
epo: 91, steps: 92 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.038118917, 'recall': 0.021473898, 'precision': 0.21382307, 'sAP10': 0.0}
====================================================================================================
==>step: 93, f_score: 0.18901555240154266, recall: 0.1287529617547989, precision:0.451376348733902, sAP10: 0.0
 
epo: 92, steps: 93 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.18901555, 'recall': 0.12875296, 'precision': 0.45137635, 'sAP10': 0.0}
====================================================================================================
==>step: 94, f_score: 0.23055623471736908, recall: 0.17667658627033234, precision:0.3705238699913025, sAP10: 0.0
 
epo: 93, steps: 94 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.23055623, 'recall': 0.17667659, 'precision': 0.37052387, 'sAP10': 0.0}
====================================================================================================
==>step: 95, f_score: 0.2635623514652252, recall: 0.20787544548511505, precision:0.39367759227752686, sAP10: 0.0
 
epo: 94, steps: 95 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.26356235, 'recall': 0.20787545, 'precision': 0.3936776, 'sAP10': 0.0}
====================================================================================================
==>step: 96, f_score: 0.312316358089447, recall: 0.2602725625038147, precision:0.4213820993900299, sAP10: 0.0
 
epo: 95, steps: 96 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.31231636, 'recall': 0.26027256, 'precision': 0.4213821, 'sAP10': 0.0}
====================================================================================================
==>step: 97, f_score: 0.36346784234046936, recall: 0.32156944274902344, precision:0.44493672251701355, sAP10: 0.0
 
epo: 96, steps: 97 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.36346784, 'recall': 0.32156944, 'precision': 0.44493672, 'sAP10': 0.0}
====================================================================================================
==>step: 98, f_score: 0.3962441086769104, recall: 0.37379705905914307, precision:0.44805794954299927, sAP10: 0.0
 
epo: 97, steps: 98 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.3962441, 'recall': 0.37379706, 'precision': 0.44805795, 'sAP10': 0.0}
====================================================================================================
==>step: 99, f_score: 0.42564016580581665, recall: 0.43058550357818604, precision:0.4416646957397461, sAP10: 0.0
 
epo: 98, steps: 99 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.42564017, 'recall': 0.4305855, 'precision': 0.4416647, 'sAP10': 0.0}
====================================================================================================
==>step: 100, f_score: 0.42148691415786743, recall: 0.4633651375770569, precision:0.40765365958213806, sAP10: 0.0
 
epo: 99, steps: 100 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.4214869, 'recall': 0.46336514, 'precision': 0.40765366, 'sAP10': 0.0}
====================================================================================================
==>step: 101, f_score: 0.43134453892707825, recall: 0.47442376613616943, precision:0.41609975695610046, sAP10: 0.0
 
epo: 100, steps: 101 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.43134454, 'recall': 0.47442377, 'precision': 0.41609976, 'sAP10': 0.0}
====================================================================================================
==>step: 102, f_score: 0.4150458574295044, recall: 0.4644445478916168, precision:0.397470086812973, sAP10: 0.0
 
epo: 101, steps: 102 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.41504586, 'recall': 0.46444455, 'precision': 0.3974701, 'sAP10': 0.0}
====================================================================================================
==>step: 103, f_score: 0.4404905140399933, recall: 0.48171180486679077, precision:0.4261496961116791, sAP10: 0.0
 
epo: 102, steps: 103 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.4404905, 'recall': 0.4817118, 'precision': 0.4261497, 'sAP10': 0.0}
====================================================================================================
==>step: 104, f_score: 0.4454377591609955, recall: 0.4847978353500366, precision:0.43254926800727844, sAP10: 0.0
 
epo: 103, steps: 104 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.44543776, 'recall': 0.48479784, 'precision': 0.43254927, 'sAP10': 0.0}
====================================================================================================
==>step: 105, f_score: 0.44725295901298523, recall: 0.48226210474967957, precision:0.43773847818374634, sAP10: 0.0
 
epo: 104, steps: 105 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.44725296, 'recall': 0.4822621, 'precision': 0.43773848, 'sAP10': 0.0}
====================================================================================================
==>step: 106, f_score: 0.4525749981403351, recall: 0.48297861218452454, precision:0.4473836123943329, sAP10: 0.0
 
epo: 105, steps: 106 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.452575, 'recall': 0.4829786, 'precision': 0.4473836, 'sAP10': 0.0}
====================================================================================================
==>step: 107, f_score: 0.46643126010894775, recall: 0.49718233942985535, precision:0.4608173370361328, sAP10: 0.0
 
epo: 106, steps: 107 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.46643126, 'recall': 0.49718234, 'precision': 0.46081734, 'sAP10': 0.0}
====================================================================================================
==>step: 108, f_score: 0.4712736904621124, recall: 0.49863186478614807, precision:0.46847793459892273, sAP10: 0.0
 
epo: 107, steps: 108 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.4712737, 'recall': 0.49863186, 'precision': 0.46847793, 'sAP10': 0.0}
====================================================================================================
==>step: 109, f_score: 0.47658130526542664, recall: 0.5015175342559814, precision:0.4764697253704071, sAP10: 0.0
 
epo: 108, steps: 109 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.4765813, 'recall': 0.50151753, 'precision': 0.47646973, 'sAP10': 0.0}
====================================================================================================
==>step: 110, f_score: 0.4876568019390106, recall: 0.5107811689376831, precision:0.4894193112850189, sAP10: 0.0
 
epo: 109, steps: 110 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.4876568, 'recall': 0.51078117, 'precision': 0.4894193, 'sAP10': 0.0}
====================================================================================================
==>step: 111, f_score: 0.49938902258872986, recall: 0.5214221477508545, precision:0.5004147291183472, sAP10: 0.0
 
epo: 110, steps: 111 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.49938902, 'recall': 0.52142215, 'precision': 0.5004147, 'sAP10': 0.0}
====================================================================================================
==>step: 112, f_score: 0.5081117153167725, recall: 0.5278855562210083, precision:0.5101787447929382, sAP10: 0.0
 
epo: 111, steps: 112 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5081117, 'recall': 0.52788556, 'precision': 0.51017874, 'sAP10': 0.0}
====================================================================================================
==>step: 113, f_score: 0.5169547200202942, recall: 0.5389794707298279, precision:0.5195665955543518, sAP10: 0.0
 
epo: 112, steps: 113 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5169547, 'recall': 0.5389795, 'precision': 0.5195666, 'sAP10': 0.0}
====================================================================================================
==>step: 114, f_score: 0.5205355882644653, recall: 0.5404086112976074, precision:0.5244133472442627, sAP10: 0.0
 
epo: 113, steps: 114 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5205356, 'recall': 0.5404086, 'precision': 0.52441335, 'sAP10': 0.0}
====================================================================================================
==>step: 115, f_score: 0.5318787097930908, recall: 0.5573031902313232, precision:0.5306702852249146, sAP10: 0.0
 
epo: 114, steps: 115 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5318787, 'recall': 0.5573032, 'precision': 0.5306703, 'sAP10': 0.0}
====================================================================================================
==>step: 116, f_score: 0.5308523774147034, recall: 0.5572094917297363, precision:0.5286567807197571, sAP10: 0.0
 
epo: 115, steps: 116 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5308524, 'recall': 0.5572095, 'precision': 0.5286568, 'sAP10': 0.0}
====================================================================================================
==>step: 117, f_score: 0.5392374396324158, recall: 0.56186842918396, precision:0.541482150554657, sAP10: 0.0
 
epo: 116, steps: 117 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.53923744, 'recall': 0.5618684, 'precision': 0.54148215, 'sAP10': 0.0}
====================================================================================================
==>step: 118, f_score: 0.5515657067298889, recall: 0.5742443799972534, precision:0.5536568760871887, sAP10: 0.0
 
epo: 117, steps: 118 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5515657, 'recall': 0.5742444, 'precision': 0.5536569, 'sAP10': 0.0}
====================================================================================================
==>step: 119, f_score: 0.5530983209609985, recall: 0.578571081161499, precision:0.5520213842391968, sAP10: 0.0
 
epo: 118, steps: 119 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5530983, 'recall': 0.5785711, 'precision': 0.5520214, 'sAP10': 0.0}
====================================================================================================
==>step: 120, f_score: 0.5643848776817322, recall: 0.58951735496521, precision:0.5645647644996643, sAP10: 0.0
 
epo: 119, steps: 120 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5643849, 'recall': 0.58951735, 'precision': 0.56456476, 'sAP10': 0.0}
====================================================================================================
==>step: 121, f_score: 0.5724730491638184, recall: 0.5968979001045227, precision:0.5722724199295044, sAP10: 0.0
 
epo: 120, steps: 121 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.57247305, 'recall': 0.5968979, 'precision': 0.5722724, 'sAP10': 0.0}
====================================================================================================
==>step: 122, f_score: 0.5738537907600403, recall: 0.6008133292198181, precision:0.5725736618041992, sAP10: 0.0
 
epo: 121, steps: 122 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5738538, 'recall': 0.6008133, 'precision': 0.57257366, 'sAP10': 0.0}
====================================================================================================
==>step: 123, f_score: 0.572751522064209, recall: 0.600007951259613, precision:0.5712063312530518, sAP10: 0.0
 
epo: 122, steps: 123 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5727515, 'recall': 0.60000795, 'precision': 0.57120633, 'sAP10': 0.0}
====================================================================================================
==>step: 124, f_score: 0.5803592205047607, recall: 0.6078001856803894, precision:0.5783568024635315, sAP10: 0.0
 
epo: 123, steps: 124 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5803592, 'recall': 0.6078002, 'precision': 0.5783568, 'sAP10': 0.0}
====================================================================================================
==>step: 125, f_score: 0.5807958245277405, recall: 0.6144245862960815, precision:0.5730709433555603, sAP10: 0.0
 
epo: 124, steps: 125 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5807958, 'recall': 0.6144246, 'precision': 0.57307094, 'sAP10': 0.0}
====================================================================================================
==>step: 126, f_score: 0.5800646543502808, recall: 0.6163014769554138, precision:0.5691336393356323, sAP10: 0.0
 
epo: 125, steps: 126 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.58006465, 'recall': 0.6163015, 'precision': 0.56913364, 'sAP10': 0.0}
====================================================================================================
==>step: 127, f_score: 0.5737568140029907, recall: 0.6105836033821106, precision:0.5620095729827881, sAP10: 0.0
 
epo: 126, steps: 127 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5737568, 'recall': 0.6105836, 'precision': 0.5620096, 'sAP10': 0.0}
====================================================================================================
==>step: 128, f_score: 0.5723897218704224, recall: 0.6123917102813721, precision:0.558012843132019, sAP10: 0.0
 
epo: 127, steps: 128 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5723897, 'recall': 0.6123917, 'precision': 0.55801284, 'sAP10': 0.0}
====================================================================================================
==>step: 129, f_score: 0.5824488401412964, recall: 0.6269180774688721, precision:0.5648886561393738, sAP10: 0.0
 
epo: 128, steps: 129 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.58244884, 'recall': 0.6269181, 'precision': 0.56488866, 'sAP10': 0.0}
====================================================================================================
==>step: 130, f_score: 0.5930278897285461, recall: 0.6374730467796326, precision:0.5743433833122253, sAP10: 0.0
 
epo: 129, steps: 130 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5930279, 'recall': 0.63747305, 'precision': 0.5743434, 'sAP10': 0.0}
====================================================================================================
==>step: 131, f_score: 0.5991066098213196, recall: 0.6451308727264404, precision:0.5788972973823547, sAP10: 0.0
 
epo: 130, steps: 131 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.5991066, 'recall': 0.6451309, 'precision': 0.5788973, 'sAP10': 0.0}
====================================================================================================
==>step: 132, f_score: 0.598753035068512, recall: 0.6481189131736755, precision:0.5758538842201233, sAP10: 0.0
 
epo: 131, steps: 132 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.59875304, 'recall': 0.6481189, 'precision': 0.5758539, 'sAP10': 0.0}
====================================================================================================
==>step: 133, f_score: 0.6120587587356567, recall: 0.6583737730979919, precision:0.5919514298439026, sAP10: 0.0
 
epo: 132, steps: 133 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.61205876, 'recall': 0.6583738, 'precision': 0.59195143, 'sAP10': 0.0}
====================================================================================================
==>step: 134, f_score: 0.6223000288009644, recall: 0.6607058048248291, precision:0.6062254905700684, sAP10: 0.0
 
epo: 133, steps: 134 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.6223, 'recall': 0.6607058, 'precision': 0.6062255, 'sAP10': 0.0}
====================================================================================================
==>step: 135, f_score: 0.6395132541656494, recall: 0.6743581295013428, precision:0.6283871531486511, sAP10: 0.0
 
epo: 134, steps: 135 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.63951325, 'recall': 0.6743581, 'precision': 0.62838715, 'sAP10': 0.0}
====================================================================================================
==>step: 136, f_score: 0.6405999660491943, recall: 0.6784189939498901, precision:0.6270405054092407, sAP10: 0.0
 
epo: 135, steps: 136 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.64059997, 'recall': 0.678419, 'precision': 0.6270405, 'sAP10': 0.0}
====================================================================================================
==>step: 137, f_score: 0.6490727663040161, recall: 0.6793899536132812, precision:0.6441693305969238, sAP10: 0.0
 
epo: 136, steps: 137 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.64907277, 'recall': 0.67938995, 'precision': 0.64416933, 'sAP10': 0.0}
====================================================================================================
==>step: 138, f_score: 0.6549440026283264, recall: 0.6816921830177307, precision:0.652836263179779, sAP10: 0.0
 
epo: 137, steps: 138 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.654944, 'recall': 0.6816922, 'precision': 0.65283626, 'sAP10': 0.0}
====================================================================================================
==>step: 139, f_score: 0.6600964665412903, recall: 0.688283383846283, precision:0.655083954334259, sAP10: 0.0
 
epo: 138, steps: 139 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.66009647, 'recall': 0.6882834, 'precision': 0.65508395, 'sAP10': 0.0}
====================================================================================================
==>step: 140, f_score: 0.6611244082450867, recall: 0.6942160129547119, precision:0.6521039605140686, sAP10: 0.0
 
epo: 139, steps: 140 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.6611244, 'recall': 0.694216, 'precision': 0.65210396, 'sAP10': 0.0}
====================================================================================================
==>step: 141, f_score: 0.6639329195022583, recall: 0.6947677135467529, precision:0.6578735709190369, sAP10: 0.0
 
epo: 140, steps: 141 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.6639329, 'recall': 0.6947677, 'precision': 0.6578736, 'sAP10': 0.0}
====================================================================================================
==>step: 142, f_score: 0.6676334142684937, recall: 0.7008465528488159, precision:0.6587008833885193, sAP10: 0.0
 
epo: 141, steps: 142 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.6676334, 'recall': 0.70084655, 'precision': 0.6587009, 'sAP10': 0.0}
====================================================================================================
==>step: 143, f_score: 0.6709124445915222, recall: 0.7064829468727112, precision:0.6598836183547974, sAP10: 0.0
 
epo: 142, steps: 143 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.67091244, 'recall': 0.70648295, 'precision': 0.6598836, 'sAP10': 0.0}
====================================================================================================
==>step: 144, f_score: 0.6676416993141174, recall: 0.7066904902458191, precision:0.6521359086036682, sAP10: 0.0
 
epo: 143, steps: 144 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.6676417, 'recall': 0.7066905, 'precision': 0.6521359, 'sAP10': 0.0}
====================================================================================================
==>step: 145, f_score: 0.6622797846794128, recall: 0.7034207582473755, precision:0.6428536772727966, sAP10: 0.0
 
epo: 144, steps: 145 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.6622798, 'recall': 0.70342076, 'precision': 0.6428537, 'sAP10': 0.0}
====================================================================================================
==>step: 146, f_score: 0.662713348865509, recall: 0.7044883370399475, precision:0.642995297908783, sAP10: 0.0
 
epo: 145, steps: 146 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.66271335, 'recall': 0.70448834, 'precision': 0.6429953, 'sAP10': 0.0}
====================================================================================================
==>step: 147, f_score: 0.6782091856002808, recall: 0.714270293712616, precision:0.6647769808769226, sAP10: 0.0
 
epo: 146, steps: 147 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.6782092, 'recall': 0.7142703, 'precision': 0.664777, 'sAP10': 0.0}
====================================================================================================
==>step: 148, f_score: 0.6857555508613586, recall: 0.7171865105628967, precision:0.6776378750801086, sAP10: 0.0
 
epo: 147, steps: 148 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.68575555, 'recall': 0.7171865, 'precision': 0.6776379, 'sAP10': 0.0}
====================================================================================================
==>step: 149, f_score: 0.6903194189071655, recall: 0.7133582234382629, precision:0.6902754902839661, sAP10: 0.0
 
epo: 148, steps: 149 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.6903194, 'recall': 0.7133582, 'precision': 0.6902755, 'sAP10': 0.0}
====================================================================================================
==>step: 150, f_score: 0.6895986199378967, recall: 0.7105312943458557, precision:0.6919270753860474, sAP10: 0.0
 
epo: 149, steps: 150 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.6895986, 'recall': 0.7105313, 'precision': 0.6919271, 'sAP10': 0.0}
====================================================================================================
==>step: 151, f_score: 0.6882669925689697, recall: 0.7117089629173279, precision:0.6883417963981628, sAP10: 0.0
 
epo: 150, steps: 151 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.688267, 'recall': 0.71170896, 'precision': 0.6883418, 'sAP10': 0.0}
====================================================================================================
==>step: 152, f_score: 0.6868942975997925, recall: 0.7153319120407104, precision:0.6819506883621216, sAP10: 0.0
 
epo: 151, steps: 152 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.6868943, 'recall': 0.7153319, 'precision': 0.6819507, 'sAP10': 0.0}
====================================================================================================
==>step: 153, f_score: 0.6848750710487366, recall: 0.7162361145019531, precision:0.6769000887870789, sAP10: 0.0
 
epo: 152, steps: 153 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.6848751, 'recall': 0.7162361, 'precision': 0.6769001, 'sAP10': 0.0}
====================================================================================================
==>step: 154, f_score: 0.6826918125152588, recall: 0.7151700258255005, precision:0.6747710704803467, sAP10: 0.0
 
epo: 153, steps: 154 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.6826918, 'recall': 0.71517, 'precision': 0.6747711, 'sAP10': 0.0}
====================================================================================================
==>step: 155, f_score: 0.6759170293807983, recall: 0.7155295610427856, precision:0.6608736515045166, sAP10: 0.0
 
epo: 154, steps: 155 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.675917, 'recall': 0.71552956, 'precision': 0.66087365, 'sAP10': 0.0}
====================================================================================================
