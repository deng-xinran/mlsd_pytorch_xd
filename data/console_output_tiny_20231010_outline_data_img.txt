using config:  mlsd_pytorch/configs/mobilev2_mlsd_tiny_512_base2_bsize24.yaml
datasets:
  input_size: 512
  name: wireframe
  with_centermap_extend: False
decode:
  len_thresh: 5
  score_thresh: 0.05
  top_k: 500
loss:
  focal_loss_level: 0
  loss_type: 1*L1
  loss_weight_dict_list: [{'tp_center_loss': 10.0, 'sol_center_loss': 1.0, 'tp_match_loss': 1.0}]
  match_sap_thresh: 5.0
  with_focal_loss: True
  with_match_loss: False
  with_sol_loss: True
model:
  model_name: mobilev2_mlsd
  num_classes: 1
  with_deconv: True
sys:
  cpu: False
  gpus: 1
  num_workers: 8
train:
  adam_epsilon: 1e-06
  batch_size: 24
  cache_to_mem: False
  data_cache_dir: ./data/wireframe_cache/
  device_ids: [0]
  device_ids_str: 0
  do_train: True
  dropout: 0.1
  early_stop_n: 200
  gradient_accumulation_steps: 1
  img_dir: ./data/wireframe_raw/images/
  label_fn: ./data/wireframe_raw/train.json
  learning_rate: 0.003
  load_from: 
  log_steps: 50
  lr_decay_gamma: 0.2
  milestones: [50, 100, 150]
  milestones_in_epo: True
  num_train_epochs: 155
  num_workers: 8
  save_dir: ./workdir/models/mobilev2_mlsd_tiny_512_bsize242023-10-10T09:32:22.183887/
  use_step_lr_policy: True
  warmup_steps: 100
  weight_decay: 1e-06
  with_cache: False
val:
  batch_size: 8
  img_dir: ./data/wireframe_raw/images/
  label_fn: ./data/wireframe_raw/valid.json
  val_after_epoch: 50
==> load label..
==> valid samples:  48
==> load label..
==> valid samples:  15
MobileV2_MLSD(
  (backbone): MobileNetV2(
    (features): Sequential(
      (0): ConvBNReLU(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (block12): BlockTypeA(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (block13): BlockTypeB(
    (conv1): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (block14): BlockTypeA(
    (conv1): Sequential(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (block15): BlockTypeB(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (block16): BlockTypeC(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(5, 5), dilation=(5, 5))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv3): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
  )
  (block17): BilinearConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
)
===> loss weight:  {'tp_center_loss': 10.0, 'tp_displacement_loss': 1.0, 'tp_len_loss': 1.0, 'tp_angle_loss': 1.0, 'tp_match_loss': 1.0, 'tp_centerness_loss': 1.0, 'sol_center_loss': 1.0, 'sol_displacement_loss': 1.0, 'sol_len_loss': 1.0, 'sol_angle_loss': 1.0, 'sol_match_loss': 1.0, 'sol_centerness_loss': 1.0, 'line_seg_loss': 1.0, 'junc_seg_loss': 1.0}
==>step: 104, f_score: 0.2699383497238159, recall: 0.46261948347091675, precision:0.20852722227573395, sAP10: 0.0
 
epo: 51, steps: 104 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.26993835, 'recall': 0.46261948, 'precision': 0.20852722, 'sAP10': 0.0}
====================================================================================================
==>step: 106, f_score: 0.2758428156375885, recall: 0.48376744985580444, precision:0.21196453273296356, sAP10: 0.0
 
epo: 52, steps: 106 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.27584282, 'recall': 0.48376745, 'precision': 0.21196453, 'sAP10': 0.0}
====================================================================================================
==>step: 108, f_score: 0.29639357328414917, recall: 0.4936183989048004, precision:0.22840124368667603, sAP10: 0.0
 
epo: 53, steps: 108 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.29639357, 'recall': 0.4936184, 'precision': 0.22840124, 'sAP10': 0.0}
====================================================================================================
==>step: 110, f_score: 0.3279511332511902, recall: 0.5060034990310669, precision:0.2622806131839752, sAP10: 0.0
 
epo: 54, steps: 110 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.32795113, 'recall': 0.5060035, 'precision': 0.2622806, 'sAP10': 0.0}
====================================================================================================
==>step: 112, f_score: 0.35048454999923706, recall: 0.5080001354217529, precision:0.28908571600914, sAP10: 0.0
 
epo: 55, steps: 112 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.35048455, 'recall': 0.50800014, 'precision': 0.28908572, 'sAP10': 0.0}
====================================================================================================
==>step: 114, f_score: 0.35081154108047485, recall: 0.4682634472846985, precision:0.3186637759208679, sAP10: 0.0
 
epo: 56, steps: 114 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.35081154, 'recall': 0.46826345, 'precision': 0.31866378, 'sAP10': 0.0}
====================================================================================================
==>step: 116, f_score: 0.3382739722728729, recall: 0.4249995946884155, precision:0.32989755272865295, sAP10: 0.0
 
epo: 57, steps: 116 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.33827397, 'recall': 0.4249996, 'precision': 0.32989755, 'sAP10': 0.0}
====================================================================================================
==>step: 118, f_score: 0.32599937915802, recall: 0.40057364106178284, precision:0.325108140707016, sAP10: 0.0
 
epo: 58, steps: 118 ,sAP10 : 0.0000 , best sAP10: 0.0000
{'fscore': 0.32599938, 'recall': 0.40057364, 'precision': 0.32510814, 'sAP10': 0.0}
====================================================================================================
==>step: 120, f_score: 0.3037300705909729, recall: 0.3732866048812866, precision:0.31379783153533936, sAP10: 0.19607843137254902
 
epo: 59, steps: 120 ,sAP10 : 0.1961 , best sAP10: 0.1961
{'fscore': 0.30373007, 'recall': 0.3732866, 'precision': 0.31379783, 'sAP10': 0.19607843137254902}
====================================================================================================
==>step: 122, f_score: 0.28254833817481995, recall: 0.35116106271743774, precision:0.281421959400177, sAP10: 0.0
 
epo: 60, steps: 122 ,sAP10 : 0.0000 , best sAP10: 0.1961
{'fscore': 0.28254834, 'recall': 0.35116106, 'precision': 0.28142196, 'sAP10': 0.0}
====================================================================================================
==>step: 124, f_score: 0.19939391314983368, recall: 0.25102514028549194, precision:0.18306154012680054, sAP10: 0.0
 
epo: 61, steps: 124 ,sAP10 : 0.0000 , best sAP10: 0.1961
{'fscore': 0.19939391, 'recall': 0.25102514, 'precision': 0.18306154, 'sAP10': 0.0}
====================================================================================================
==>step: 126, f_score: 0.18960393965244293, recall: 0.23028162121772766, precision:0.17980742454528809, sAP10: 0.0
 
epo: 62, steps: 126 ,sAP10 : 0.0000 , best sAP10: 0.1961
{'fscore': 0.18960394, 'recall': 0.23028162, 'precision': 0.17980742, 'sAP10': 0.0}
====================================================================================================
==>step: 128, f_score: 0.18615327775478363, recall: 0.22469177842140198, precision:0.17410977184772491, sAP10: 0.0
 
epo: 63, steps: 128 ,sAP10 : 0.0000 , best sAP10: 0.1961
{'fscore': 0.18615328, 'recall': 0.22469178, 'precision': 0.17410977, 'sAP10': 0.0}
====================================================================================================
==>step: 130, f_score: 0.1970764696598053, recall: 0.27004995942115784, precision:0.1711886078119278, sAP10: 0.0
 
epo: 64, steps: 130 ,sAP10 : 0.0000 , best sAP10: 0.1961
{'fscore': 0.19707647, 'recall': 0.27004996, 'precision': 0.17118861, 'sAP10': 0.0}
====================================================================================================
==>step: 132, f_score: 0.250185489654541, recall: 0.32217222452163696, precision:0.23775969445705414, sAP10: 0.0
 
epo: 65, steps: 132 ,sAP10 : 0.0000 , best sAP10: 0.1961
{'fscore': 0.2501855, 'recall': 0.32217222, 'precision': 0.2377597, 'sAP10': 0.0}
====================================================================================================
==>step: 134, f_score: 0.18842387199401855, recall: 0.23168958723545074, precision:0.18904025852680206, sAP10: 0.0
 
epo: 66, steps: 134 ,sAP10 : 0.0000 , best sAP10: 0.1961
{'fscore': 0.18842387, 'recall': 0.23168959, 'precision': 0.18904026, 'sAP10': 0.0}
====================================================================================================
==>step: 136, f_score: 0.13210971653461456, recall: 0.16585703194141388, precision:0.11707982420921326, sAP10: 0.0
 
epo: 67, steps: 136 ,sAP10 : 0.0000 , best sAP10: 0.1961
{'fscore': 0.13210972, 'recall': 0.16585703, 'precision': 0.117079824, 'sAP10': 0.0}
====================================================================================================
==>step: 138, f_score: 0.14432987570762634, recall: 0.18294285237789154, precision:0.13107332587242126, sAP10: 0.0
 
epo: 68, steps: 138 ,sAP10 : 0.0000 , best sAP10: 0.1961
{'fscore': 0.14432988, 'recall': 0.18294285, 'precision': 0.13107333, 'sAP10': 0.0}
====================================================================================================
==>step: 140, f_score: 0.1825573742389679, recall: 0.2615813612937927, precision:0.15230993926525116, sAP10: 0.2564102564102564
 
epo: 69, steps: 140 ,sAP10 : 0.2564 , best sAP10: 0.2564
{'fscore': 0.18255737, 'recall': 0.26158136, 'precision': 0.15230994, 'sAP10': 0.2564102564102564}
====================================================================================================
==>step: 142, f_score: 0.2069072425365448, recall: 0.2883322834968567, precision:0.17051468789577484, sAP10: 0.0
 
epo: 70, steps: 142 ,sAP10 : 0.0000 , best sAP10: 0.2564
{'fscore': 0.20690724, 'recall': 0.28833228, 'precision': 0.17051469, 'sAP10': 0.0}
====================================================================================================
==>step: 144, f_score: 0.2160492241382599, recall: 0.2872592806816101, precision:0.18320627510547638, sAP10: 0.0
 
epo: 71, steps: 144 ,sAP10 : 0.0000 , best sAP10: 0.2564
{'fscore': 0.21604922, 'recall': 0.28725928, 'precision': 0.18320628, 'sAP10': 0.0}
====================================================================================================
==>step: 146, f_score: 0.21330717206001282, recall: 0.267961323261261, precision:0.19104696810245514, sAP10: 0.0
 
epo: 72, steps: 146 ,sAP10 : 0.0000 , best sAP10: 0.2564
{'fscore': 0.21330717, 'recall': 0.26796132, 'precision': 0.19104697, 'sAP10': 0.0}
====================================================================================================
==>step: 148, f_score: 0.200397789478302, recall: 0.24856796860694885, precision:0.17887043952941895, sAP10: 0.0
 
epo: 73, steps: 148 ,sAP10 : 0.0000 , best sAP10: 0.2564
{'fscore': 0.20039779, 'recall': 0.24856797, 'precision': 0.17887044, 'sAP10': 0.0}
====================================================================================================
==>step: 150, f_score: 0.2432178407907486, recall: 0.30228739976882935, precision:0.22837623953819275, sAP10: 0.0
 
epo: 74, steps: 150 ,sAP10 : 0.0000 , best sAP10: 0.2564
{'fscore': 0.24321784, 'recall': 0.3022874, 'precision': 0.22837624, 'sAP10': 0.0}
====================================================================================================
==>step: 152, f_score: 0.24572105705738068, recall: 0.29175055027008057, precision:0.24511376023292542, sAP10: 0.0
 
epo: 75, steps: 152 ,sAP10 : 0.0000 , best sAP10: 0.2564
{'fscore': 0.24572106, 'recall': 0.29175055, 'precision': 0.24511376, 'sAP10': 0.0}
====================================================================================================
==>step: 154, f_score: 0.23111338913440704, recall: 0.2706683278083801, precision:0.22831903398036957, sAP10: 0.0
 
epo: 76, steps: 154 ,sAP10 : 0.0000 , best sAP10: 0.2564
{'fscore': 0.23111339, 'recall': 0.27066833, 'precision': 0.22831903, 'sAP10': 0.0}
====================================================================================================
==>step: 156, f_score: 0.2664770185947418, recall: 0.31854549050331116, precision:0.25366735458374023, sAP10: 0.6666666666666667
 
epo: 77, steps: 156 ,sAP10 : 0.6667 , best sAP10: 0.6667
{'fscore': 0.26647702, 'recall': 0.3185455, 'precision': 0.25366735, 'sAP10': 0.6666666666666667}
====================================================================================================
==>step: 158, f_score: 0.30133533477783203, recall: 0.35911065340042114, precision:0.28497278690338135, sAP10: 0.0
 
epo: 78, steps: 158 ,sAP10 : 0.0000 , best sAP10: 0.6667
{'fscore': 0.30133533, 'recall': 0.35911065, 'precision': 0.2849728, 'sAP10': 0.0}
====================================================================================================
==>step: 160, f_score: 0.29224836826324463, recall: 0.3370952904224396, precision:0.29545891284942627, sAP10: 0.0
 
epo: 79, steps: 160 ,sAP10 : 0.0000 , best sAP10: 0.6667
{'fscore': 0.29224837, 'recall': 0.3370953, 'precision': 0.2954589, 'sAP10': 0.0}
====================================================================================================
==>step: 162, f_score: 0.3175932466983795, recall: 0.4117375314235687, precision:0.2785947024822235, sAP10: 0.021231422505307854
 
epo: 80, steps: 162 ,sAP10 : 0.0212 , best sAP10: 0.6667
{'fscore': 0.31759325, 'recall': 0.41173753, 'precision': 0.2785947, 'sAP10': 0.021231422505307854}
====================================================================================================
==>step: 164, f_score: 0.31873926520347595, recall: 0.41334426403045654, precision:0.2909637987613678, sAP10: 1.6666666666666667
 
epo: 81, steps: 164 ,sAP10 : 1.6667 , best sAP10: 1.6667
{'fscore': 0.31873927, 'recall': 0.41334426, 'precision': 0.2909638, 'sAP10': 1.6666666666666667}
====================================================================================================
==>step: 166, f_score: 0.25101155042648315, recall: 0.3060959279537201, precision:0.23787006735801697, sAP10: 0.0
 
epo: 82, steps: 166 ,sAP10 : 0.0000 , best sAP10: 1.6667
{'fscore': 0.25101155, 'recall': 0.30609593, 'precision': 0.23787007, 'sAP10': 0.0}
====================================================================================================
==>step: 168, f_score: 0.22151966392993927, recall: 0.26163971424102783, precision:0.21930299699306488, sAP10: 0.0
 
epo: 83, steps: 168 ,sAP10 : 0.0000 , best sAP10: 1.6667
{'fscore': 0.22151966, 'recall': 0.2616397, 'precision': 0.219303, 'sAP10': 0.0}
====================================================================================================
==>step: 170, f_score: 0.2665235698223114, recall: 0.32534974813461304, precision:0.2580040395259857, sAP10: 0.0
 
epo: 84, steps: 170 ,sAP10 : 0.0000 , best sAP10: 1.6667
{'fscore': 0.26652357, 'recall': 0.32534975, 'precision': 0.25800404, 'sAP10': 0.0}
====================================================================================================
==>step: 172, f_score: 0.29562559723854065, recall: 0.3696143925189972, precision:0.279184490442276, sAP10: 1.111111111111111
 
epo: 85, steps: 172 ,sAP10 : 1.1111 , best sAP10: 1.6667
{'fscore': 0.2956256, 'recall': 0.3696144, 'precision': 0.2791845, 'sAP10': 1.111111111111111}
====================================================================================================
==>step: 174, f_score: 0.36831608414649963, recall: 0.43842360377311707, precision:0.353819876909256, sAP10: 0.09803921568627448
 
epo: 86, steps: 174 ,sAP10 : 0.0980 , best sAP10: 1.6667
{'fscore': 0.36831608, 'recall': 0.4384236, 'precision': 0.35381988, 'sAP10': 0.09803921568627448}
====================================================================================================
==>step: 176, f_score: 0.40801170468330383, recall: 0.5067778825759888, precision:0.3699110746383667, sAP10: 0.10437710437710439
 
epo: 87, steps: 176 ,sAP10 : 0.1044 , best sAP10: 1.6667
{'fscore': 0.4080117, 'recall': 0.5067779, 'precision': 0.36991107, 'sAP10': 0.10437710437710439}
====================================================================================================
==>step: 178, f_score: 0.4796568751335144, recall: 0.6106968522071838, precision:0.44187992811203003, sAP10: 3.5830241187384044
 
epo: 88, steps: 178 ,sAP10 : 3.5830 , best sAP10: 3.5830
{'fscore': 0.47965688, 'recall': 0.61069685, 'precision': 0.44187993, 'sAP10': 3.5830241187384044}
====================================================================================================
==>step: 180, f_score: 0.3557797968387604, recall: 0.45060834288597107, precision:0.32928377389907837, sAP10: 4.801801801801801
 
epo: 89, steps: 180 ,sAP10 : 4.8018 , best sAP10: 4.8018
{'fscore': 0.3557798, 'recall': 0.45060834, 'precision': 0.32928377, 'sAP10': 4.801801801801801}
====================================================================================================
==>step: 182, f_score: 0.2070196568965912, recall: 0.27255693078041077, precision:0.17831522226333618, sAP10: 3.3333333333333335
 
epo: 90, steps: 182 ,sAP10 : 3.3333 , best sAP10: 4.8018
{'fscore': 0.20701966, 'recall': 0.27255693, 'precision': 0.17831522, 'sAP10': 3.3333333333333335}
====================================================================================================
==>step: 184, f_score: 0.21340522170066833, recall: 0.269416868686676, precision:0.19496798515319824, sAP10: 1.6666666666666667
 
epo: 91, steps: 184 ,sAP10 : 1.6667 , best sAP10: 4.8018
{'fscore': 0.21340522, 'recall': 0.26941687, 'precision': 0.19496799, 'sAP10': 1.6666666666666667}
====================================================================================================
==>step: 186, f_score: 0.29613083600997925, recall: 0.36829015612602234, precision:0.280534565448761, sAP10: 0.0
 
epo: 92, steps: 186 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.29613084, 'recall': 0.36829016, 'precision': 0.28053457, 'sAP10': 0.0}
====================================================================================================
==>step: 188, f_score: 0.36176902055740356, recall: 0.4341200590133667, precision:0.3294290602207184, sAP10: 0.9848484848484848
 
epo: 93, steps: 188 ,sAP10 : 0.9848 , best sAP10: 4.8018
{'fscore': 0.36176902, 'recall': 0.43412006, 'precision': 0.32942906, 'sAP10': 0.9848484848484848}
====================================================================================================
==>step: 190, f_score: 0.4059775173664093, recall: 0.500281572341919, precision:0.3554896414279938, sAP10: 0.47619047619047616
 
epo: 94, steps: 190 ,sAP10 : 0.4762 , best sAP10: 4.8018
{'fscore': 0.40597752, 'recall': 0.5002816, 'precision': 0.35548964, 'sAP10': 0.47619047619047616}
====================================================================================================
==>step: 192, f_score: 0.4087635576725006, recall: 0.5149756073951721, precision:0.35294005274772644, sAP10: 0.16396213657876943
 
epo: 95, steps: 192 ,sAP10 : 0.1640 , best sAP10: 4.8018
{'fscore': 0.40876356, 'recall': 0.5149756, 'precision': 0.35294005, 'sAP10': 0.16396213657876943}
====================================================================================================
==>step: 194, f_score: 0.35002315044403076, recall: 0.4378611147403717, precision:0.3112463355064392, sAP10: 0.01488095238095238
 
epo: 96, steps: 194 ,sAP10 : 0.0149 , best sAP10: 4.8018
{'fscore': 0.35002315, 'recall': 0.4378611, 'precision': 0.31124634, 'sAP10': 0.01488095238095238}
====================================================================================================
==>step: 196, f_score: 0.23631344735622406, recall: 0.28814929723739624, precision:0.2154248207807541, sAP10: 0.0
 
epo: 97, steps: 196 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.23631345, 'recall': 0.2881493, 'precision': 0.21542482, 'sAP10': 0.0}
====================================================================================================
==>step: 198, f_score: 0.3067915141582489, recall: 0.41829681396484375, precision:0.2632543742656708, sAP10: 0.0
 
epo: 98, steps: 198 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.3067915, 'recall': 0.4182968, 'precision': 0.26325437, 'sAP10': 0.0}
====================================================================================================
==>step: 200, f_score: 0.44320234656333923, recall: 0.6796185970306396, precision:0.3544745147228241, sAP10: 0.0
 
epo: 99, steps: 200 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.44320235, 'recall': 0.6796186, 'precision': 0.3544745, 'sAP10': 0.0}
====================================================================================================
==>step: 202, f_score: 0.44986119866371155, recall: 0.6480369567871094, precision:0.37853866815567017, sAP10: 0.0
 
epo: 100, steps: 202 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.4498612, 'recall': 0.64803696, 'precision': 0.37853867, 'sAP10': 0.0}
====================================================================================================
==>step: 204, f_score: 0.41814008355140686, recall: 0.5840381383895874, precision:0.3556268513202667, sAP10: 0.03401360544217687
 
epo: 101, steps: 204 ,sAP10 : 0.0340 , best sAP10: 4.8018
{'fscore': 0.41814008, 'recall': 0.58403814, 'precision': 0.35562685, 'sAP10': 0.03401360544217687}
====================================================================================================
==>step: 206, f_score: 0.3852882385253906, recall: 0.5065373182296753, precision:0.3433944284915924, sAP10: 0.45212765957446804
 
epo: 102, steps: 206 ,sAP10 : 0.4521 , best sAP10: 4.8018
{'fscore': 0.38528824, 'recall': 0.5065373, 'precision': 0.34339443, 'sAP10': 0.45212765957446804}
====================================================================================================
==>step: 208, f_score: 0.39816322922706604, recall: 0.5224962830543518, precision:0.3513403832912445, sAP10: 0.5102040816326531
 
epo: 103, steps: 208 ,sAP10 : 0.5102 , best sAP10: 4.8018
{'fscore': 0.39816323, 'recall': 0.5224963, 'precision': 0.35134038, 'sAP10': 0.5102040816326531}
====================================================================================================
==>step: 210, f_score: 0.4156174659729004, recall: 0.5653724670410156, precision:0.3474990427494049, sAP10: 0.3703703703703704
 
epo: 104, steps: 210 ,sAP10 : 0.3704 , best sAP10: 4.8018
{'fscore': 0.41561747, 'recall': 0.56537247, 'precision': 0.34749904, 'sAP10': 0.3703703703703704}
====================================================================================================
==>step: 212, f_score: 0.4201887547969818, recall: 0.580879271030426, precision:0.3487103581428528, sAP10: 0.3703703703703704
 
epo: 105, steps: 212 ,sAP10 : 0.3704 , best sAP10: 4.8018
{'fscore': 0.42018875, 'recall': 0.5808793, 'precision': 0.34871036, 'sAP10': 0.3703703703703704}
====================================================================================================
==>step: 214, f_score: 0.42980000376701355, recall: 0.6028100252151489, precision:0.3560858368873596, sAP10: 0.0
 
epo: 106, steps: 214 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.4298, 'recall': 0.60281, 'precision': 0.35608584, 'sAP10': 0.0}
====================================================================================================
==>step: 216, f_score: 0.4449421167373657, recall: 0.6326667666435242, precision:0.3595636487007141, sAP10: 0.0
 
epo: 107, steps: 216 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.44494212, 'recall': 0.63266677, 'precision': 0.35956365, 'sAP10': 0.0}
====================================================================================================
==>step: 218, f_score: 0.4251849353313446, recall: 0.5954543948173523, precision:0.3475930988788605, sAP10: 0.23420479302832245
 
epo: 108, steps: 218 ,sAP10 : 0.2342 , best sAP10: 4.8018
{'fscore': 0.42518494, 'recall': 0.5954544, 'precision': 0.3475931, 'sAP10': 0.23420479302832245}
====================================================================================================
==>step: 220, f_score: 0.38419878482818604, recall: 0.5280289053916931, precision:0.33118441700935364, sAP10: 0.25277777777777777
 
epo: 109, steps: 220 ,sAP10 : 0.2528 , best sAP10: 4.8018
{'fscore': 0.38419878, 'recall': 0.5280289, 'precision': 0.33118442, 'sAP10': 0.25277777777777777}
====================================================================================================
==>step: 222, f_score: 0.3779144883155823, recall: 0.49800872802734375, precision:0.3314734995365143, sAP10: 0.2564102564102564
 
epo: 110, steps: 222 ,sAP10 : 0.2564 , best sAP10: 4.8018
{'fscore': 0.3779145, 'recall': 0.49800873, 'precision': 0.3314735, 'sAP10': 0.2564102564102564}
====================================================================================================
==>step: 224, f_score: 0.3641701936721802, recall: 0.4713039696216583, precision:0.31708991527557373, sAP10: 0.13333333333333333
 
epo: 111, steps: 224 ,sAP10 : 0.1333 , best sAP10: 4.8018
{'fscore': 0.3641702, 'recall': 0.47130397, 'precision': 0.31708992, 'sAP10': 0.13333333333333333}
====================================================================================================
==>step: 226, f_score: 0.3218890130519867, recall: 0.3950193524360657, precision:0.29599303007125854, sAP10: 0.0
 
epo: 112, steps: 226 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.321889, 'recall': 0.39501935, 'precision': 0.29599303, 'sAP10': 0.0}
====================================================================================================
==>step: 228, f_score: 0.3622126281261444, recall: 0.4776565432548523, precision:0.31155726313591003, sAP10: 0.0
 
epo: 113, steps: 228 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.36221263, 'recall': 0.47765654, 'precision': 0.31155726, 'sAP10': 0.0}
====================================================================================================
==>step: 230, f_score: 0.387062132358551, recall: 0.5117174386978149, precision:0.3327487111091614, sAP10: 0.0
 
epo: 114, steps: 230 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.38706213, 'recall': 0.51171744, 'precision': 0.3327487, 'sAP10': 0.0}
====================================================================================================
==>step: 232, f_score: 0.38930705189704895, recall: 0.5241138339042664, precision:0.332295298576355, sAP10: 0.0
 
epo: 115, steps: 232 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.38930705, 'recall': 0.52411383, 'precision': 0.3322953, 'sAP10': 0.0}
====================================================================================================
==>step: 234, f_score: 0.3888011872768402, recall: 0.5421127080917358, precision:0.32202690839767456, sAP10: 0.0
 
epo: 116, steps: 234 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.3888012, 'recall': 0.5421127, 'precision': 0.3220269, 'sAP10': 0.0}
====================================================================================================
==>step: 236, f_score: 0.3896724283695221, recall: 0.5390233397483826, precision:0.32538965344429016, sAP10: 0.0
 
epo: 117, steps: 236 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.38967243, 'recall': 0.53902334, 'precision': 0.32538965, 'sAP10': 0.0}
====================================================================================================
==>step: 238, f_score: 0.3677329421043396, recall: 0.5104191899299622, precision:0.30490103363990784, sAP10: 0.0
 
epo: 118, steps: 238 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.36773294, 'recall': 0.5104192, 'precision': 0.30490103, 'sAP10': 0.0}
====================================================================================================
==>step: 240, f_score: 0.3313002288341522, recall: 0.4473026692867279, precision:0.28532516956329346, sAP10: 0.0
 
epo: 119, steps: 240 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.33130023, 'recall': 0.44730267, 'precision': 0.28532517, 'sAP10': 0.0}
====================================================================================================
==>step: 242, f_score: 0.3223603367805481, recall: 0.43586304783821106, precision:0.2783059775829315, sAP10: 0.0
 
epo: 120, steps: 242 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.32236034, 'recall': 0.43586305, 'precision': 0.27830598, 'sAP10': 0.0}
====================================================================================================
==>step: 244, f_score: 0.32754552364349365, recall: 0.4615303874015808, precision:0.27288609743118286, sAP10: 0.0
 
epo: 121, steps: 244 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.32754552, 'recall': 0.4615304, 'precision': 0.2728861, 'sAP10': 0.0}
====================================================================================================
==>step: 246, f_score: 0.326208233833313, recall: 0.4607425630092621, precision:0.2698806822299957, sAP10: 0.0
 
epo: 122, steps: 246 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.32620823, 'recall': 0.46074256, 'precision': 0.26988068, 'sAP10': 0.0}
====================================================================================================
==>step: 248, f_score: 0.35002660751342773, recall: 0.4875113368034363, precision:0.29179176688194275, sAP10: 0.0
 
epo: 123, steps: 248 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.3500266, 'recall': 0.48751134, 'precision': 0.29179177, 'sAP10': 0.0}
====================================================================================================
==>step: 250, f_score: 0.3803633451461792, recall: 0.53205806016922, precision:0.3107409179210663, sAP10: 0.0
 
epo: 124, steps: 250 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.38036335, 'recall': 0.53205806, 'precision': 0.31074092, 'sAP10': 0.0}
====================================================================================================
==>step: 252, f_score: 0.3805760443210602, recall: 0.5293216705322266, precision:0.3116833567619324, sAP10: 0.0
 
epo: 125, steps: 252 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.38057604, 'recall': 0.5293217, 'precision': 0.31168336, 'sAP10': 0.0}
====================================================================================================
==>step: 254, f_score: 0.39100196957588196, recall: 0.5451107025146484, precision:0.3175240457057953, sAP10: 0.0
 
epo: 126, steps: 254 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.39100197, 'recall': 0.5451107, 'precision': 0.31752405, 'sAP10': 0.0}
====================================================================================================
==>step: 256, f_score: 0.38832899928092957, recall: 0.5272684693336487, precision:0.32623711228370667, sAP10: 0.33333333333333337
 
epo: 127, steps: 256 ,sAP10 : 0.3333 , best sAP10: 4.8018
{'fscore': 0.388329, 'recall': 0.52726847, 'precision': 0.3262371, 'sAP10': 0.33333333333333337}
====================================================================================================
==>step: 258, f_score: 0.3721042573451996, recall: 0.5061743259429932, precision:0.31269368529319763, sAP10: 0.0
 
epo: 128, steps: 258 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.37210426, 'recall': 0.5061743, 'precision': 0.3126937, 'sAP10': 0.0}
====================================================================================================
==>step: 260, f_score: 0.3503623604774475, recall: 0.4615136384963989, precision:0.3030410408973694, sAP10: 0.8333333333333334
 
epo: 129, steps: 260 ,sAP10 : 0.8333 , best sAP10: 4.8018
{'fscore': 0.35036236, 'recall': 0.46151364, 'precision': 0.30304104, 'sAP10': 0.8333333333333334}
====================================================================================================
==>step: 262, f_score: 0.3459309935569763, recall: 0.4601811468601227, precision:0.3007604777812958, sAP10: 1.1111111111111112
 
epo: 130, steps: 262 ,sAP10 : 1.1111 , best sAP10: 4.8018
{'fscore': 0.345931, 'recall': 0.46018115, 'precision': 0.30076048, 'sAP10': 1.1111111111111112}
====================================================================================================
==>step: 264, f_score: 0.3371341824531555, recall: 0.44349077343940735, precision:0.2929903268814087, sAP10: 0.47619047619047616
 
epo: 131, steps: 264 ,sAP10 : 0.4762 , best sAP10: 4.8018
{'fscore': 0.33713418, 'recall': 0.44349077, 'precision': 0.29299033, 'sAP10': 0.47619047619047616}
====================================================================================================
==>step: 266, f_score: 0.367021381855011, recall: 0.4948616921901703, precision:0.3086293637752533, sAP10: 0.47619047619047616
 
epo: 132, steps: 266 ,sAP10 : 0.4762 , best sAP10: 4.8018
{'fscore': 0.36702138, 'recall': 0.4948617, 'precision': 0.30862936, 'sAP10': 0.47619047619047616}
====================================================================================================
==>step: 268, f_score: 0.39833104610443115, recall: 0.5354143381118774, precision:0.33592426776885986, sAP10: 0.47619047619047616
 
epo: 133, steps: 268 ,sAP10 : 0.4762 , best sAP10: 4.8018
{'fscore': 0.39833105, 'recall': 0.53541434, 'precision': 0.33592427, 'sAP10': 0.47619047619047616}
====================================================================================================
==>step: 270, f_score: 0.37681588530540466, recall: 0.5049287676811218, precision:0.3163394033908844, sAP10: 0.47619047619047616
 
epo: 134, steps: 270 ,sAP10 : 0.4762 , best sAP10: 4.8018
{'fscore': 0.3768159, 'recall': 0.50492877, 'precision': 0.3163394, 'sAP10': 0.47619047619047616}
====================================================================================================
==>step: 272, f_score: 0.3586973547935486, recall: 0.46809595823287964, precision:0.3066178858280182, sAP10: 0.0
 
epo: 135, steps: 272 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.35869735, 'recall': 0.46809596, 'precision': 0.3066179, 'sAP10': 0.0}
====================================================================================================
==>step: 274, f_score: 0.35892611742019653, recall: 0.47500523924827576, precision:0.3036864995956421, sAP10: 0.0
 
epo: 136, steps: 274 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.35892612, 'recall': 0.47500524, 'precision': 0.3036865, 'sAP10': 0.0}
====================================================================================================
==>step: 276, f_score: 0.3428950309753418, recall: 0.45880699157714844, precision:0.2918822467327118, sAP10: 0.0
 
epo: 137, steps: 276 ,sAP10 : 0.0000 , best sAP10: 4.8018
{'fscore': 0.34289503, 'recall': 0.458807, 'precision': 0.29188225, 'sAP10': 0.0}
====================================================================================================
==>step: 278, f_score: 0.3675752878189087, recall: 0.49967625737190247, precision:0.3065555691719055, sAP10: 0.5797101449275364
 
epo: 138, steps: 278 ,sAP10 : 0.5797 , best sAP10: 4.8018
{'fscore': 0.3675753, 'recall': 0.49967626, 'precision': 0.30655557, 'sAP10': 0.5797101449275364}
====================================================================================================
==>step: 280, f_score: 0.39134126901626587, recall: 0.5239245295524597, precision:0.32979995012283325, sAP10: 0.6666666666666667
 
epo: 139, steps: 280 ,sAP10 : 0.6667 , best sAP10: 4.8018
{'fscore': 0.39134127, 'recall': 0.5239245, 'precision': 0.32979995, 'sAP10': 0.6666666666666667}
====================================================================================================
==>step: 282, f_score: 0.4197852909564972, recall: 0.5803238749504089, precision:0.33826255798339844, sAP10: 0.008658008658008658
 
epo: 140, steps: 282 ,sAP10 : 0.0087 , best sAP10: 4.8018
{'fscore': 0.4197853, 'recall': 0.5803239, 'precision': 0.33826256, 'sAP10': 0.008658008658008658}
====================================================================================================
==>step: 284, f_score: 0.41119351983070374, recall: 0.5713796615600586, precision:0.3320196270942688, sAP10: 0.010131712259371832
 
epo: 141, steps: 284 ,sAP10 : 0.0101 , best sAP10: 4.8018
{'fscore': 0.41119352, 'recall': 0.57137966, 'precision': 0.33201963, 'sAP10': 0.010131712259371832}
====================================================================================================
==>step: 286, f_score: 0.40940359234809875, recall: 0.5741195678710938, precision:0.32872387766838074, sAP10: 0.4447198127495526
 
epo: 142, steps: 286 ,sAP10 : 0.4447 , best sAP10: 4.8018
{'fscore': 0.4094036, 'recall': 0.57411957, 'precision': 0.32872388, 'sAP10': 0.4447198127495526}
====================================================================================================
==>step: 288, f_score: 0.45662328600883484, recall: 0.633767306804657, precision:0.372898668050766, sAP10: 0.4629629629629629
 
epo: 143, steps: 288 ,sAP10 : 0.4630 , best sAP10: 4.8018
{'fscore': 0.4566233, 'recall': 0.6337673, 'precision': 0.37289867, 'sAP10': 0.4629629629629629}
====================================================================================================
==>step: 290, f_score: 0.4135698080062866, recall: 0.5667259097099304, precision:0.3406897485256195, sAP10: 0.35353535353535354
 
epo: 144, steps: 290 ,sAP10 : 0.3535 , best sAP10: 4.8018
{'fscore': 0.4135698, 'recall': 0.5667259, 'precision': 0.34068975, 'sAP10': 0.35353535353535354}
====================================================================================================
==>step: 292, f_score: 0.41416215896606445, recall: 0.5701080560684204, precision:0.3386284112930298, sAP10: 0.30303030303030304
 
epo: 145, steps: 292 ,sAP10 : 0.3030 , best sAP10: 4.8018
{'fscore': 0.41416216, 'recall': 0.57010806, 'precision': 0.3386284, 'sAP10': 0.30303030303030304}
====================================================================================================
==>step: 294, f_score: 0.36672481894493103, recall: 0.5042704939842224, precision:0.30721715092658997, sAP10: 0.319971870604782
 
epo: 146, steps: 294 ,sAP10 : 0.3200 , best sAP10: 4.8018
{'fscore': 0.36672482, 'recall': 0.5042705, 'precision': 0.30721715, 'sAP10': 0.319971870604782}
====================================================================================================
==>step: 296, f_score: 0.3733457326889038, recall: 0.5114611387252808, precision:0.31290996074676514, sAP10: 0.018315018315018316
 
epo: 147, steps: 296 ,sAP10 : 0.0183 , best sAP10: 4.8018
{'fscore': 0.37334573, 'recall': 0.51146114, 'precision': 0.31290996, 'sAP10': 0.018315018315018316}
====================================================================================================
==>step: 298, f_score: 0.3497537076473236, recall: 0.46135011315345764, precision:0.3049938380718231, sAP10: 0.018832391713747648
 
epo: 148, steps: 298 ,sAP10 : 0.0188 , best sAP10: 4.8018
{'fscore': 0.3497537, 'recall': 0.4613501, 'precision': 0.30499384, 'sAP10': 0.018832391713747648}
====================================================================================================
==>step: 300, f_score: 0.3394710123538971, recall: 0.4396534264087677, precision:0.3003057837486267, sAP10: 0.021929824561403508
 
epo: 149, steps: 300 ,sAP10 : 0.0219 , best sAP10: 4.8018
{'fscore': 0.339471, 'recall': 0.43965343, 'precision': 0.30030578, 'sAP10': 0.021929824561403508}
====================================================================================================
==>step: 302, f_score: 0.3376064598560333, recall: 0.4382762908935547, precision:0.29890188574790955, sAP10: 0.023310023310023312
 
epo: 150, steps: 302 ,sAP10 : 0.0233 , best sAP10: 4.8018
{'fscore': 0.33760646, 'recall': 0.4382763, 'precision': 0.2989019, 'sAP10': 0.023310023310023312}
====================================================================================================
==>step: 304, f_score: 0.3584613800048828, recall: 0.48376014828681946, precision:0.303829550743103, sAP10: 0.02364066193853428
 
epo: 151, steps: 304 ,sAP10 : 0.0236 , best sAP10: 4.8018
{'fscore': 0.35846138, 'recall': 0.48376015, 'precision': 0.30382955, 'sAP10': 0.02364066193853428}
====================================================================================================
==>step: 306, f_score: 0.33682265877723694, recall: 0.44400474429130554, precision:0.2935808002948761, sAP10: 0.022675736961451247
 
epo: 152, steps: 306 ,sAP10 : 0.0227 , best sAP10: 4.8018
{'fscore': 0.33682266, 'recall': 0.44400474, 'precision': 0.2935808, 'sAP10': 0.022675736961451247}
====================================================================================================
==>step: 308, f_score: 0.3368619680404663, recall: 0.4477134943008423, precision:0.2919989824295044, sAP10: 0.02207505518763797
 
epo: 153, steps: 308 ,sAP10 : 0.0221 , best sAP10: 4.8018
{'fscore': 0.33686197, 'recall': 0.4477135, 'precision': 0.29199898, 'sAP10': 0.02207505518763797}
====================================================================================================
==>step: 310, f_score: 0.3363701105117798, recall: 0.44997450709342957, precision:0.29121658205986023, sAP10: 0.024154589371980676
 
epo: 154, steps: 310 ,sAP10 : 0.0242 , best sAP10: 4.8018
{'fscore': 0.3363701, 'recall': 0.4499745, 'precision': 0.29121658, 'sAP10': 0.024154589371980676}
====================================================================================================
