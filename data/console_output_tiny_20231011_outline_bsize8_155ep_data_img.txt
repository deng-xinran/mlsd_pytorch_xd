using config:  mlsd_pytorch/configs/mobilev2_mlsd_tiny_512_base2_bsize8_155ep.yaml
datasets:
  input_size: 512
  name: wireframe
  with_centermap_extend: False
decode:
  len_thresh: 5
  score_thresh: 0.05
  top_k: 500
loss:
  focal_loss_level: 0
  loss_type: 1*L1
  loss_weight_dict_list: [{'tp_center_loss': 10.0, 'sol_center_loss': 1.0, 'tp_match_loss': 1.0}]
  match_sap_thresh: 5.0
  with_focal_loss: True
  with_match_loss: False
  with_sol_loss: True
model:
  model_name: mobilev2_mlsd
  num_classes: 1
  with_deconv: True
sys:
  cpu: False
  gpus: 1
  num_workers: 8
train:
  adam_epsilon: 1e-06
  batch_size: 8
  cache_to_mem: False
  data_cache_dir: ./data/wireframe_cache/
  device_ids: [0]
  device_ids_str: 0
  do_train: True
  dropout: 0.1
  early_stop_n: 200
  gradient_accumulation_steps: 1
  img_dir: ./data/wireframe_raw/images/
  label_fn: ./data/wireframe_raw/train.json
  learning_rate: 0.003
  load_from: 
  log_steps: 50
  lr_decay_gamma: 0.2
  milestones: [50, 100, 150]
  milestones_in_epo: True
  num_train_epochs: 155
  num_workers: 8
  save_dir: ./workdir/models/mobilev2_mlsd_tiny_512_bsize8_LR0012023-10-12T11:59:18.636681/
  use_step_lr_policy: True
  warmup_steps: 100
  weight_decay: 1e-06
  with_cache: False
val:
  batch_size: 5
  img_dir: ./data/wireframe_raw/images/
  label_fn: ./data/wireframe_raw/valid.json
  val_after_epoch: 50
==> load label..
==> valid samples:  48
==> load label..
==> valid samples:  15
MobileV2_MLSD(
  (backbone): MobileNetV2(
    (features): Sequential(
      (0): ConvBNReLU(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (block12): BlockTypeA(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (block13): BlockTypeB(
    (conv1): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (block14): BlockTypeA(
    (conv1): Sequential(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (block15): BlockTypeB(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (block16): BlockTypeC(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(5, 5), dilation=(5, 5))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv3): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
  )
  (block17): BilinearConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
)
===> loss weight:  {'tp_center_loss': 10.0, 'tp_displacement_loss': 1.0, 'tp_len_loss': 1.0, 'tp_angle_loss': 1.0, 'tp_match_loss': 1.0, 'tp_centerness_loss': 1.0, 'sol_center_loss': 1.0, 'sol_displacement_loss': 1.0, 'sol_len_loss': 1.0, 'sol_angle_loss': 1.0, 'sol_match_loss': 1.0, 'sol_centerness_loss': 1.0, 'line_seg_loss': 1.0, 'junc_seg_loss': 1.0}
==>step: 312, f_score: 0.4458121955394745, recall: 0.9990959763526917, precision:0.29038479924201965, sAP10: 0.7420608024715649
 
epo: 51, steps: 312 ,sAP10 : 0.7421 , best sAP10: 0.7421
{'fscore': 0.4458122, 'recall': 0.999096, 'precision': 0.2903848, 'sAP10': 0.7420608024715649}
====================================================================================================
==>step: 318, f_score: 0.4595465362071991, recall: 0.987337052822113, precision:0.3061075210571289, sAP10: 0.7838848846053971
 
epo: 52, steps: 318 ,sAP10 : 0.7839 , best sAP10: 0.7839
{'fscore': 0.45954654, 'recall': 0.98733705, 'precision': 0.30610752, 'sAP10': 0.7838848846053971}
====================================================================================================
==>step: 324, f_score: 0.4245055019855499, recall: 0.9969659447669983, precision:0.27446338534355164, sAP10: 1.329397275091109
 
epo: 53, steps: 324 ,sAP10 : 1.3294 , best sAP10: 1.3294
{'fscore': 0.4245055, 'recall': 0.99696594, 'precision': 0.2744634, 'sAP10': 1.329397275091109}
====================================================================================================
==>step: 330, f_score: 0.4091586172580719, recall: 0.99912428855896, precision:0.26177844405174255, sAP10: 1.2166426967243624
 
epo: 54, steps: 330 ,sAP10 : 1.2166 , best sAP10: 1.3294
{'fscore': 0.40915862, 'recall': 0.9991243, 'precision': 0.26177844, 'sAP10': 1.2166426967243624}
====================================================================================================
==>step: 336, f_score: 0.4367421269416809, recall: 0.997488796710968, precision:0.28614601492881775, sAP10: 0.5403788738496416
 
epo: 55, steps: 336 ,sAP10 : 0.5404 , best sAP10: 1.3294
{'fscore': 0.43674213, 'recall': 0.9974888, 'precision': 0.28614601, 'sAP10': 0.5403788738496416}
====================================================================================================
==>step: 342, f_score: 0.44496631622314453, recall: 0.9935283660888672, precision:0.29328805208206177, sAP10: 0.575301239481801
 
epo: 56, steps: 342 ,sAP10 : 0.5753 , best sAP10: 1.3294
{'fscore': 0.44496632, 'recall': 0.99352837, 'precision': 0.29328805, 'sAP10': 0.575301239481801}
====================================================================================================
==>step: 348, f_score: 0.43282800912857056, recall: 0.9965006709098816, precision:0.2819976806640625, sAP10: 1.4266538585990403
 
epo: 57, steps: 348 ,sAP10 : 1.4267 , best sAP10: 1.4267
{'fscore': 0.432828, 'recall': 0.9965007, 'precision': 0.28199768, 'sAP10': 1.4266538585990403}
====================================================================================================
==>step: 354, f_score: 0.45455217361450195, recall: 0.99714195728302, precision:0.30035585165023804, sAP10: 1.2059630800210903
 
epo: 58, steps: 354 ,sAP10 : 1.2060 , best sAP10: 1.4267
{'fscore': 0.45455217, 'recall': 0.99714196, 'precision': 0.30035585, 'sAP10': 1.2059630800210903}
====================================================================================================
==>step: 360, f_score: 0.42815250158309937, recall: 0.9983989596366882, precision:0.27834072709083557, sAP10: 1.8566892744888253
 
epo: 59, steps: 360 ,sAP10 : 1.8567 , best sAP10: 1.8567
{'fscore': 0.4281525, 'recall': 0.99839896, 'precision': 0.27834073, 'sAP10': 1.8566892744888253}
====================================================================================================
==>step: 366, f_score: 0.4082331359386444, recall: 0.9993153810501099, precision:0.2619718909263611, sAP10: 1.4067194948697281
 
epo: 60, steps: 366 ,sAP10 : 1.4067 , best sAP10: 1.8567
{'fscore': 0.40823314, 'recall': 0.9993154, 'precision': 0.2619719, 'sAP10': 1.4067194948697281}
====================================================================================================
==>step: 372, f_score: 0.42695340514183044, recall: 0.9981969594955444, precision:0.277314692735672, sAP10: 0.5255364963898193
 
epo: 61, steps: 372 ,sAP10 : 0.5255 , best sAP10: 1.8567
{'fscore': 0.4269534, 'recall': 0.99819696, 'precision': 0.2773147, 'sAP10': 0.5255364963898193}
====================================================================================================
==>step: 378, f_score: 0.41368386149406433, recall: 0.9973998665809631, precision:0.266083687543869, sAP10: 0.5384492508433187
 
epo: 62, steps: 378 ,sAP10 : 0.5384 , best sAP10: 1.8567
{'fscore': 0.41368386, 'recall': 0.99739987, 'precision': 0.2660837, 'sAP10': 0.5384492508433187}
====================================================================================================
==>step: 384, f_score: 0.4128069579601288, recall: 0.9974896907806396, precision:0.2647855579853058, sAP10: 0.4837567665582883
 
epo: 63, steps: 384 ,sAP10 : 0.4838 , best sAP10: 1.8567
{'fscore': 0.41280696, 'recall': 0.9974897, 'precision': 0.26478556, 'sAP10': 0.4837567665582883}
====================================================================================================
==>step: 390, f_score: 0.4404663145542145, recall: 0.9921335577964783, precision:0.2900395095348358, sAP10: 1.6525376146818145
 
epo: 64, steps: 390 ,sAP10 : 1.6525 , best sAP10: 1.8567
{'fscore': 0.4404663, 'recall': 0.99213356, 'precision': 0.2900395, 'sAP10': 1.6525376146818145}
====================================================================================================
==>step: 396, f_score: 0.4532546103000641, recall: 0.9944142699241638, precision:0.30098646879196167, sAP10: 1.8558670269733717
 
epo: 65, steps: 396 ,sAP10 : 1.8559 , best sAP10: 1.8567
{'fscore': 0.4532546, 'recall': 0.99441427, 'precision': 0.30098647, 'sAP10': 1.8558670269733717}
====================================================================================================
==>step: 402, f_score: 0.43093451857566833, recall: 0.9959695339202881, precision:0.28139129281044006, sAP10: 2.279584326778843
 
epo: 66, steps: 402 ,sAP10 : 2.2796 , best sAP10: 2.2796
{'fscore': 0.43093452, 'recall': 0.99596953, 'precision': 0.2813913, 'sAP10': 2.279584326778843}
====================================================================================================
==>step: 408, f_score: 0.44468173384666443, recall: 0.9942491054534912, precision:0.2936028242111206, sAP10: 4.857889562321912
 
epo: 67, steps: 408 ,sAP10 : 4.8579 , best sAP10: 4.8579
{'fscore': 0.44468173, 'recall': 0.9942491, 'precision': 0.29360282, 'sAP10': 4.857889562321912}
====================================================================================================
==>step: 414, f_score: 0.4598259925842285, recall: 0.9935337901115417, precision:0.30600693821907043, sAP10: 2.2225527990095384
 
epo: 68, steps: 414 ,sAP10 : 2.2226 , best sAP10: 4.8579
{'fscore': 0.459826, 'recall': 0.9935338, 'precision': 0.30600694, 'sAP10': 2.2225527990095384}
====================================================================================================
==>step: 420, f_score: 0.46182677149772644, recall: 0.9955471754074097, precision:0.3074709177017212, sAP10: 0.37468641738347774
 
epo: 69, steps: 420 ,sAP10 : 0.3747 , best sAP10: 4.8579
{'fscore': 0.46182677, 'recall': 0.9955472, 'precision': 0.30747092, 'sAP10': 0.37468641738347774}
====================================================================================================
==>step: 426, f_score: 0.44737961888313293, recall: 0.9963595867156982, precision:0.29391658306121826, sAP10: 2.0206491313045154
 
epo: 70, steps: 426 ,sAP10 : 2.0206 , best sAP10: 4.8579
{'fscore': 0.44737962, 'recall': 0.9963596, 'precision': 0.29391658, 'sAP10': 2.0206491313045154}
====================================================================================================
==>step: 432, f_score: 0.4394129812717438, recall: 0.9968661069869995, precision:0.2876058518886566, sAP10: 1.8814275615527294
 
epo: 71, steps: 432 ,sAP10 : 1.8814 , best sAP10: 4.8579
{'fscore': 0.43941298, 'recall': 0.9968661, 'precision': 0.28760585, 'sAP10': 1.8814275615527294}
====================================================================================================
==>step: 438, f_score: 0.42754065990448, recall: 0.996432900428772, precision:0.27810975909233093, sAP10: 2.6872170135571642
 
epo: 72, steps: 438 ,sAP10 : 2.6872 , best sAP10: 4.8579
{'fscore': 0.42754066, 'recall': 0.9964329, 'precision': 0.27810976, 'sAP10': 2.6872170135571642}
====================================================================================================
==>step: 444, f_score: 0.4269043505191803, recall: 0.99370276927948, precision:0.27861663699150085, sAP10: 0.41901219546123847
 
epo: 73, steps: 444 ,sAP10 : 0.4190 , best sAP10: 4.8579
{'fscore': 0.42690435, 'recall': 0.99370277, 'precision': 0.27861664, 'sAP10': 0.41901219546123847}
====================================================================================================
==>step: 450, f_score: 0.4059408903121948, recall: 0.9885202050209045, precision:0.26051583886146545, sAP10: 0.4130684739564146
 
epo: 74, steps: 450 ,sAP10 : 0.4131 , best sAP10: 4.8579
{'fscore': 0.4059409, 'recall': 0.9885202, 'precision': 0.26051584, 'sAP10': 0.4130684739564146}
====================================================================================================
==>step: 456, f_score: 0.40731140971183777, recall: 0.9940833449363708, precision:0.26163575053215027, sAP10: 0.18748371252899626
 
epo: 75, steps: 456 ,sAP10 : 0.1875 , best sAP10: 4.8579
{'fscore': 0.4073114, 'recall': 0.99408334, 'precision': 0.26163575, 'sAP10': 0.18748371252899626}
====================================================================================================
==>step: 462, f_score: 0.42387154698371887, recall: 0.9929092526435852, precision:0.2748221158981323, sAP10: 0.6602254428341385
 
epo: 76, steps: 462 ,sAP10 : 0.6602 , best sAP10: 4.8579
{'fscore': 0.42387155, 'recall': 0.99290925, 'precision': 0.27482212, 'sAP10': 0.6602254428341385}
====================================================================================================
==>step: 468, f_score: 0.40361735224723816, recall: 0.9946234822273254, precision:0.25850430130958557, sAP10: 0.19573077960384774
 
epo: 77, steps: 468 ,sAP10 : 0.1957 , best sAP10: 4.8579
{'fscore': 0.40361735, 'recall': 0.9946235, 'precision': 0.2585043, 'sAP10': 0.19573077960384774}
====================================================================================================
==>step: 474, f_score: 0.39001601934432983, recall: 0.9958359003067017, precision:0.24794845283031464, sAP10: 0.28312135087694673
 
epo: 78, steps: 474 ,sAP10 : 0.2831 , best sAP10: 4.8579
{'fscore': 0.39001602, 'recall': 0.9958359, 'precision': 0.24794845, 'sAP10': 0.28312135087694673}
====================================================================================================
==>step: 480, f_score: 0.39450469613075256, recall: 0.9984668493270874, precision:0.2520289421081543, sAP10: 0.6344358256122962
 
epo: 79, steps: 480 ,sAP10 : 0.6344 , best sAP10: 4.8579
{'fscore': 0.3945047, 'recall': 0.99846685, 'precision': 0.25202894, 'sAP10': 0.6344358256122962}
====================================================================================================
==>step: 486, f_score: 0.4254376292228699, recall: 0.9942464232444763, precision:0.2784316837787628, sAP10: 1.5729673423046642
 
epo: 80, steps: 486 ,sAP10 : 1.5730 , best sAP10: 4.8579
{'fscore': 0.42543763, 'recall': 0.9942464, 'precision': 0.27843168, 'sAP10': 1.5729673423046642}
====================================================================================================
==>step: 492, f_score: 0.4415549337863922, recall: 0.9950639009475708, precision:0.29103145003318787, sAP10: 0.19700757272751515
 
epo: 81, steps: 492 ,sAP10 : 0.1970 , best sAP10: 4.8579
{'fscore': 0.44155493, 'recall': 0.9950639, 'precision': 0.29103145, 'sAP10': 0.19700757272751515}
====================================================================================================
==>step: 498, f_score: 0.48044726252555847, recall: 0.9858219623565674, precision:0.3262164294719696, sAP10: 3.5644392709486867
 
epo: 82, steps: 498 ,sAP10 : 3.5644 , best sAP10: 4.8579
{'fscore': 0.48044726, 'recall': 0.98582196, 'precision': 0.32621643, 'sAP10': 3.5644392709486867}
====================================================================================================
==>step: 504, f_score: 0.4344790279865265, recall: 0.9923375248908997, precision:0.286338746547699, sAP10: 3.706866627261525
 
epo: 83, steps: 504 ,sAP10 : 3.7069 , best sAP10: 4.8579
{'fscore': 0.43447903, 'recall': 0.9923375, 'precision': 0.28633875, 'sAP10': 3.706866627261525}
====================================================================================================
==>step: 510, f_score: 0.4512356221675873, recall: 0.9898113012313843, precision:0.3021913766860962, sAP10: 0.4811424140498472
 
epo: 84, steps: 510 ,sAP10 : 0.4811 , best sAP10: 4.8579
{'fscore': 0.45123562, 'recall': 0.9898113, 'precision': 0.30219138, 'sAP10': 0.4811424140498472}
====================================================================================================
==>step: 516, f_score: 0.4370100796222687, recall: 0.9972753524780273, precision:0.28724512457847595, sAP10: 0.924019569358354
 
epo: 85, steps: 516 ,sAP10 : 0.9240 , best sAP10: 4.8579
{'fscore': 0.43701008, 'recall': 0.99727535, 'precision': 0.28724512, 'sAP10': 0.924019569358354}
====================================================================================================
==>step: 522, f_score: 0.4190090596675873, recall: 0.9933993220329285, precision:0.2732204496860504, sAP10: 1.0263066248720125
 
epo: 86, steps: 522 ,sAP10 : 1.0263 , best sAP10: 4.8579
{'fscore': 0.41900906, 'recall': 0.9933993, 'precision': 0.27322045, 'sAP10': 1.0263066248720125}
====================================================================================================
==>step: 528, f_score: 0.4370342791080475, recall: 0.992807149887085, precision:0.2878236770629883, sAP10: 1.2767072107833162
 
epo: 87, steps: 528 ,sAP10 : 1.2767 , best sAP10: 4.8579
{'fscore': 0.43703428, 'recall': 0.99280715, 'precision': 0.28782368, 'sAP10': 1.2767072107833162}
====================================================================================================
==>step: 534, f_score: 0.44664904475212097, recall: 0.9955266118049622, precision:0.29365482926368713, sAP10: 0.4421480251324604
 
epo: 88, steps: 534 ,sAP10 : 0.4421 , best sAP10: 4.8579
{'fscore': 0.44664904, 'recall': 0.9955266, 'precision': 0.29365483, 'sAP10': 0.4421480251324604}
====================================================================================================
==>step: 540, f_score: 0.4565729796886444, recall: 0.992071807384491, precision:0.3036588132381439, sAP10: 1.688970668149027
 
epo: 89, steps: 540 ,sAP10 : 1.6890 , best sAP10: 4.8579
{'fscore': 0.45657298, 'recall': 0.9920718, 'precision': 0.3036588, 'sAP10': 1.688970668149027}
====================================================================================================
==>step: 546, f_score: 0.409735769033432, recall: 0.9914997816085815, precision:0.26579567790031433, sAP10: 0.49648403422671755
 
epo: 90, steps: 546 ,sAP10 : 0.4965 , best sAP10: 4.8579
{'fscore': 0.40973577, 'recall': 0.9914998, 'precision': 0.26579568, 'sAP10': 0.49648403422671755}
====================================================================================================
==>step: 552, f_score: 0.4062843322753906, recall: 0.9943873286247253, precision:0.2611485719680786, sAP10: 1.5958713017163668
 
epo: 91, steps: 552 ,sAP10 : 1.5959 , best sAP10: 4.8579
{'fscore': 0.40628433, 'recall': 0.9943873, 'precision': 0.26114857, 'sAP10': 1.5958713017163668}
====================================================================================================
==>step: 558, f_score: 0.4417266547679901, recall: 0.9913882613182068, precision:0.29051557183265686, sAP10: 1.3372228561387443
 
epo: 92, steps: 558 ,sAP10 : 1.3372 , best sAP10: 4.8579
{'fscore': 0.44172665, 'recall': 0.99138826, 'precision': 0.29051557, 'sAP10': 1.3372228561387443}
====================================================================================================
==>step: 564, f_score: 0.4278067946434021, recall: 0.9885538220405579, precision:0.2795677185058594, sAP10: 1.5030896095206163
 
epo: 93, steps: 564 ,sAP10 : 1.5031 , best sAP10: 4.8579
{'fscore': 0.4278068, 'recall': 0.9885538, 'precision': 0.27956772, 'sAP10': 1.5030896095206163}
====================================================================================================
==>step: 570, f_score: 0.40546318888664246, recall: 0.9984744191169739, precision:0.25926506519317627, sAP10: 0.969709707779697
 
epo: 94, steps: 570 ,sAP10 : 0.9697 , best sAP10: 4.8579
{'fscore': 0.4054632, 'recall': 0.9984744, 'precision': 0.25926507, 'sAP10': 0.969709707779697}
====================================================================================================
==>step: 576, f_score: 0.4157979190349579, recall: 0.9973087906837463, precision:0.26682838797569275, sAP10: 1.358658971999189
 
epo: 95, steps: 576 ,sAP10 : 1.3587 , best sAP10: 4.8579
{'fscore': 0.41579792, 'recall': 0.9973088, 'precision': 0.2668284, 'sAP10': 1.358658971999189}
====================================================================================================
==>step: 582, f_score: 0.37564072012901306, recall: 0.9993183016777039, precision:0.2350667268037796, sAP10: 0.8177444726613722
 
epo: 96, steps: 582 ,sAP10 : 0.8177 , best sAP10: 4.8579
{'fscore': 0.37564072, 'recall': 0.9993183, 'precision': 0.23506673, 'sAP10': 0.8177444726613722}
====================================================================================================
==>step: 588, f_score: 0.4130917191505432, recall: 0.9979668855667114, precision:0.2660079598426819, sAP10: 1.083724662886931
 
epo: 97, steps: 588 ,sAP10 : 1.0837 , best sAP10: 4.8579
{'fscore': 0.41309172, 'recall': 0.9979669, 'precision': 0.26600796, 'sAP10': 1.083724662886931}
====================================================================================================
==>step: 594, f_score: 0.42759257555007935, recall: 0.9931764006614685, precision:0.2781444191932678, sAP10: 0.654124724966766
 
epo: 98, steps: 594 ,sAP10 : 0.6541 , best sAP10: 4.8579
{'fscore': 0.42759258, 'recall': 0.9931764, 'precision': 0.27814442, 'sAP10': 0.654124724966766}
====================================================================================================
==>step: 600, f_score: 0.4225359559059143, recall: 0.9964744448661804, precision:0.27289944887161255, sAP10: 3.0852482415518123
 
epo: 99, steps: 600 ,sAP10 : 3.0852 , best sAP10: 4.8579
{'fscore': 0.42253596, 'recall': 0.99647444, 'precision': 0.27289945, 'sAP10': 3.0852482415518123}
====================================================================================================
==>step: 606, f_score: 0.42214953899383545, recall: 0.9954013228416443, precision:0.2725425958633423, sAP10: 3.51498805794199
 
epo: 100, steps: 606 ,sAP10 : 3.5150 , best sAP10: 4.8579
{'fscore': 0.42214954, 'recall': 0.9954013, 'precision': 0.2725426, 'sAP10': 3.51498805794199}
====================================================================================================
==>step: 612, f_score: 0.4225572943687439, recall: 0.9923706650733948, precision:0.27331507205963135, sAP10: 3.0595264148465877
 
epo: 101, steps: 612 ,sAP10 : 3.0595 , best sAP10: 4.8579
{'fscore': 0.4225573, 'recall': 0.99237067, 'precision': 0.27331507, 'sAP10': 3.0595264148465877}
====================================================================================================
==>step: 618, f_score: 0.4324706494808197, recall: 0.9911715984344482, precision:0.28287145495414734, sAP10: 2.7996700224829594
 
epo: 102, steps: 618 ,sAP10 : 2.7997 , best sAP10: 4.8579
{'fscore': 0.43247065, 'recall': 0.9911716, 'precision': 0.28287145, 'sAP10': 2.7996700224829594}
====================================================================================================
==>step: 624, f_score: 0.4297582805156708, recall: 0.9895227551460266, precision:0.2802783250808716, sAP10: 2.71088602653104
 
epo: 103, steps: 624 ,sAP10 : 2.7109 , best sAP10: 4.8579
{'fscore': 0.42975828, 'recall': 0.98952276, 'precision': 0.28027833, 'sAP10': 2.71088602653104}
====================================================================================================
==>step: 630, f_score: 0.428234726190567, recall: 0.989227294921875, precision:0.27912652492523193, sAP10: 1.4641759255151028
 
epo: 104, steps: 630 ,sAP10 : 1.4642 , best sAP10: 4.8579
{'fscore': 0.42823473, 'recall': 0.9892273, 'precision': 0.27912652, 'sAP10': 1.4641759255151028}
====================================================================================================
==>step: 636, f_score: 0.43424659967422485, recall: 0.9922024011611938, precision:0.2837814688682556, sAP10: 1.1210759383204725
 
epo: 105, steps: 636 ,sAP10 : 1.1211 , best sAP10: 4.8579
{'fscore': 0.4342466, 'recall': 0.9922024, 'precision': 0.28378147, 'sAP10': 1.1210759383204725}
====================================================================================================
==>step: 642, f_score: 0.4512423872947693, recall: 0.9893004298210144, precision:0.29864564538002014, sAP10: 2.363599355617096
 
epo: 106, steps: 642 ,sAP10 : 2.3636 , best sAP10: 4.8579
{'fscore': 0.4512424, 'recall': 0.98930043, 'precision': 0.29864565, 'sAP10': 2.363599355617096}
====================================================================================================
==>step: 648, f_score: 0.45658382773399353, recall: 0.9899202585220337, precision:0.30305442214012146, sAP10: 2.561159436560106
 
epo: 107, steps: 648 ,sAP10 : 2.5612 , best sAP10: 4.8579
{'fscore': 0.45658383, 'recall': 0.98992026, 'precision': 0.30305442, 'sAP10': 2.561159436560106}
====================================================================================================
==>step: 654, f_score: 0.45082995295524597, recall: 0.9936507940292358, precision:0.29714542627334595, sAP10: 3.6201550909758207
 
epo: 108, steps: 654 ,sAP10 : 3.6202 , best sAP10: 4.8579
{'fscore': 0.45082995, 'recall': 0.9936508, 'precision': 0.29714543, 'sAP10': 3.6201550909758207}
====================================================================================================
==>step: 660, f_score: 0.45049893856048584, recall: 0.993667721748352, precision:0.2971368730068207, sAP10: 2.420703758297676
 
epo: 109, steps: 660 ,sAP10 : 2.4207 , best sAP10: 4.8579
{'fscore': 0.45049894, 'recall': 0.9936677, 'precision': 0.29713687, 'sAP10': 2.420703758297676}
====================================================================================================
==>step: 666, f_score: 0.44862234592437744, recall: 0.9925245046615601, precision:0.29591280221939087, sAP10: 2.1591166474208565
 
epo: 110, steps: 666 ,sAP10 : 2.1591 , best sAP10: 4.8579
{'fscore': 0.44862235, 'recall': 0.9925245, 'precision': 0.2959128, 'sAP10': 2.1591166474208565}
====================================================================================================
==>step: 672, f_score: 0.4476228654384613, recall: 0.9898842573165894, precision:0.2960392236709595, sAP10: 1.932305058086941
 
epo: 111, steps: 672 ,sAP10 : 1.9323 , best sAP10: 4.8579
{'fscore': 0.44762287, 'recall': 0.98988426, 'precision': 0.29603922, 'sAP10': 1.932305058086941}
====================================================================================================
==>step: 678, f_score: 0.44199326634407043, recall: 0.9935893416404724, precision:0.2902166247367859, sAP10: 3.5608919382504287
 
epo: 112, steps: 678 ,sAP10 : 3.5609 , best sAP10: 4.8579
{'fscore': 0.44199327, 'recall': 0.99358934, 'precision': 0.29021662, 'sAP10': 3.5608919382504287}
====================================================================================================
==>step: 684, f_score: 0.4305107891559601, recall: 0.9961446523666382, precision:0.2804167568683624, sAP10: 2.2914475527954408
 
epo: 113, steps: 684 ,sAP10 : 2.2914 , best sAP10: 4.8579
{'fscore': 0.4305108, 'recall': 0.99614465, 'precision': 0.28041676, 'sAP10': 2.2914475527954408}
====================================================================================================
==>step: 690, f_score: 0.43572527170181274, recall: 0.9971021413803101, precision:0.2845233380794525, sAP10: 1.8907390136065134
 
epo: 114, steps: 690 ,sAP10 : 1.8907 , best sAP10: 4.8579
{'fscore': 0.43572527, 'recall': 0.99710214, 'precision': 0.28452334, 'sAP10': 1.8907390136065134}
====================================================================================================
==>step: 696, f_score: 0.43446263670921326, recall: 0.9969606995582581, precision:0.2834915816783905, sAP10: 2.007577267691568
 
epo: 115, steps: 696 ,sAP10 : 2.0076 , best sAP10: 4.8579
{'fscore': 0.43446264, 'recall': 0.9969607, 'precision': 0.28349158, 'sAP10': 2.007577267691568}
====================================================================================================
==>step: 702, f_score: 0.4374426603317261, recall: 0.9898163676261902, precision:0.28753936290740967, sAP10: 1.6530425416891228
 
epo: 116, steps: 702 ,sAP10 : 1.6530 , best sAP10: 4.8579
{'fscore': 0.43744266, 'recall': 0.98981637, 'precision': 0.28753936, 'sAP10': 1.6530425416891228}
====================================================================================================
==>step: 708, f_score: 0.4403458535671234, recall: 0.9915090203285217, precision:0.29038628935813904, sAP10: 1.4553884428361414
 
epo: 117, steps: 708 ,sAP10 : 1.4554 , best sAP10: 4.8579
{'fscore': 0.44034585, 'recall': 0.991509, 'precision': 0.2903863, 'sAP10': 1.4553884428361414}
====================================================================================================
==>step: 714, f_score: 0.4364694058895111, recall: 0.9955530166625977, precision:0.2854023575782776, sAP10: 1.680075087154733
 
epo: 118, steps: 714 ,sAP10 : 1.6801 , best sAP10: 4.8579
{'fscore': 0.4364694, 'recall': 0.995553, 'precision': 0.28540236, 'sAP10': 1.680075087154733}
====================================================================================================
==>step: 720, f_score: 0.42873385548591614, recall: 0.9951878786087036, precision:0.2782096862792969, sAP10: 1.9622697209299238
 
epo: 119, steps: 720 ,sAP10 : 1.9623 , best sAP10: 4.8579
{'fscore': 0.42873386, 'recall': 0.9951879, 'precision': 0.2782097, 'sAP10': 1.9622697209299238}
====================================================================================================
==>step: 726, f_score: 0.4333725869655609, recall: 0.9950155019760132, precision:0.28259575366973877, sAP10: 2.8396045399482905
 
epo: 120, steps: 726 ,sAP10 : 2.8396 , best sAP10: 4.8579
{'fscore': 0.4333726, 'recall': 0.9950155, 'precision': 0.28259575, 'sAP10': 2.8396045399482905}
====================================================================================================
==>step: 732, f_score: 0.43575775623321533, recall: 0.9954162836074829, precision:0.2839116156101227, sAP10: 2.724510696502796
 
epo: 121, steps: 732 ,sAP10 : 2.7245 , best sAP10: 4.8579
{'fscore': 0.43575776, 'recall': 0.9954163, 'precision': 0.28391162, 'sAP10': 2.724510696502796}
====================================================================================================
==>step: 738, f_score: 0.4386371970176697, recall: 0.9980908632278442, precision:0.28610551357269287, sAP10: 1.8487574036408587
 
epo: 122, steps: 738 ,sAP10 : 1.8488 , best sAP10: 4.8579
{'fscore': 0.4386372, 'recall': 0.99809086, 'precision': 0.2861055, 'sAP10': 1.8487574036408587}
====================================================================================================
==>step: 744, f_score: 0.4514446258544922, recall: 0.9968915581703186, precision:0.29653218388557434, sAP10: 2.5975972730422074
 
epo: 123, steps: 744 ,sAP10 : 2.5976 , best sAP10: 4.8579
{'fscore': 0.45144463, 'recall': 0.99689156, 'precision': 0.29653218, 'sAP10': 2.5975972730422074}
====================================================================================================
==>step: 750, f_score: 0.45862308144569397, recall: 0.995702862739563, precision:0.30279281735420227, sAP10: 2.6533865110266257
 
epo: 124, steps: 750 ,sAP10 : 2.6534 , best sAP10: 4.8579
{'fscore': 0.45862308, 'recall': 0.99570286, 'precision': 0.30279282, 'sAP10': 2.6533865110266257}
====================================================================================================
==>step: 756, f_score: 0.45028990507125854, recall: 0.9967867136001587, precision:0.295698344707489, sAP10: 0.973194930572978
 
epo: 125, steps: 756 ,sAP10 : 0.9732 , best sAP10: 4.8579
{'fscore': 0.4502899, 'recall': 0.9967867, 'precision': 0.29569834, 'sAP10': 0.973194930572978}
====================================================================================================
==>step: 762, f_score: 0.44942155480384827, recall: 0.9966154098510742, precision:0.2954148054122925, sAP10: 1.606176459400026
 
epo: 126, steps: 762 ,sAP10 : 1.6062 , best sAP10: 4.8579
{'fscore': 0.44942155, 'recall': 0.9966154, 'precision': 0.2954148, 'sAP10': 1.606176459400026}
====================================================================================================
==>step: 768, f_score: 0.4514422118663788, recall: 0.9932383298873901, precision:0.2989928424358368, sAP10: 1.8356893737693682
 
epo: 127, steps: 768 ,sAP10 : 1.8357 , best sAP10: 4.8579
{'fscore': 0.4514422, 'recall': 0.99323833, 'precision': 0.29899284, 'sAP10': 1.8356893737693682}
====================================================================================================
==>step: 774, f_score: 0.4463578462600708, recall: 0.9944648742675781, precision:0.29298219084739685, sAP10: 2.0213095870990605
 
epo: 128, steps: 774 ,sAP10 : 2.0213 , best sAP10: 4.8579
{'fscore': 0.44635785, 'recall': 0.9944649, 'precision': 0.2929822, 'sAP10': 2.0213095870990605}
====================================================================================================
==>step: 780, f_score: 0.44535475969314575, recall: 0.9958860874176025, precision:0.29197609424591064, sAP10: 0.9835864613492278
 
epo: 129, steps: 780 ,sAP10 : 0.9836 , best sAP10: 4.8579
{'fscore': 0.44535476, 'recall': 0.9958861, 'precision': 0.2919761, 'sAP10': 0.9835864613492278}
====================================================================================================
==>step: 786, f_score: 0.44515201449394226, recall: 0.996890127658844, precision:0.29182201623916626, sAP10: 1.649452525609755
 
epo: 130, steps: 786 ,sAP10 : 1.6495 , best sAP10: 4.8579
{'fscore': 0.445152, 'recall': 0.9968901, 'precision': 0.29182202, 'sAP10': 1.649452525609755}
====================================================================================================
==>step: 792, f_score: 0.4537203907966614, recall: 0.9967710375785828, precision:0.29892417788505554, sAP10: 1.6050408207916207
 
epo: 131, steps: 792 ,sAP10 : 1.6050 , best sAP10: 4.8579
{'fscore': 0.4537204, 'recall': 0.99677104, 'precision': 0.29892418, 'sAP10': 1.6050408207916207}
====================================================================================================
==>step: 798, f_score: 0.44527333974838257, recall: 0.9960264563560486, precision:0.29196861386299133, sAP10: 1.2668394263630576
 
epo: 132, steps: 798 ,sAP10 : 1.2668 , best sAP10: 4.8579
{'fscore': 0.44527334, 'recall': 0.99602646, 'precision': 0.2919686, 'sAP10': 1.2668394263630576}
====================================================================================================
==>step: 804, f_score: 0.43654340505599976, recall: 0.997261643409729, precision:0.28460055589675903, sAP10: 0.7263727295274462
 
epo: 133, steps: 804 ,sAP10 : 0.7264 , best sAP10: 4.8579
{'fscore': 0.4365434, 'recall': 0.99726164, 'precision': 0.28460056, 'sAP10': 0.7263727295274462}
====================================================================================================
==>step: 810, f_score: 0.43224382400512695, recall: 0.9960618615150452, precision:0.28083351254463196, sAP10: 1.9975598112883062
 
epo: 134, steps: 810 ,sAP10 : 1.9976 , best sAP10: 4.8579
{'fscore': 0.43224382, 'recall': 0.99606186, 'precision': 0.2808335, 'sAP10': 1.9975598112883062}
====================================================================================================
==>step: 816, f_score: 0.43942907452583313, recall: 0.9968263506889343, precision:0.28721413016319275, sAP10: 1.921750030980332
 
epo: 135, steps: 816 ,sAP10 : 1.9218 , best sAP10: 4.8579
{'fscore': 0.43942907, 'recall': 0.99682635, 'precision': 0.28721413, 'sAP10': 1.921750030980332}
====================================================================================================
==>step: 822, f_score: 0.443217396736145, recall: 0.9972549080848694, precision:0.29030948877334595, sAP10: 1.1244923163545029
 
epo: 136, steps: 822 ,sAP10 : 1.1245 , best sAP10: 4.8579
{'fscore': 0.4432174, 'recall': 0.9972549, 'precision': 0.2903095, 'sAP10': 1.1244923163545029}
====================================================================================================
==>step: 828, f_score: 0.44295600056648254, recall: 0.9961204528808594, precision:0.29000920057296753, sAP10: 0.4173352363474037
 
epo: 137, steps: 828 ,sAP10 : 0.4173 , best sAP10: 4.8579
{'fscore': 0.442956, 'recall': 0.99612045, 'precision': 0.2900092, 'sAP10': 0.4173352363474037}
====================================================================================================
==>step: 834, f_score: 0.4409598708152771, recall: 0.9954221248626709, precision:0.28872156143188477, sAP10: 0.6389943834147387
 
epo: 138, steps: 834 ,sAP10 : 0.6390 , best sAP10: 4.8579
{'fscore': 0.44095987, 'recall': 0.9954221, 'precision': 0.28872156, 'sAP10': 0.6389943834147387}
====================================================================================================
==>step: 840, f_score: 0.4337047040462494, recall: 0.9949399828910828, precision:0.28242799639701843, sAP10: 1.059160556175463
 
epo: 139, steps: 840 ,sAP10 : 1.0592 , best sAP10: 4.8579
{'fscore': 0.4337047, 'recall': 0.99494, 'precision': 0.282428, 'sAP10': 1.059160556175463}
====================================================================================================
==>step: 846, f_score: 0.44019195437431335, recall: 0.9946215748786926, precision:0.2885605990886688, sAP10: 0.6690174785947156
 
epo: 140, steps: 846 ,sAP10 : 0.6690 , best sAP10: 4.8579
{'fscore': 0.44019195, 'recall': 0.9946216, 'precision': 0.2885606, 'sAP10': 0.6690174785947156}
====================================================================================================
==>step: 852, f_score: 0.4401955008506775, recall: 0.9852995276451111, precision:0.2904440462589264, sAP10: 0.6209832622111511
 
epo: 141, steps: 852 ,sAP10 : 0.6210 , best sAP10: 4.8579
{'fscore': 0.4401955, 'recall': 0.9852995, 'precision': 0.29044405, 'sAP10': 0.6209832622111511}
====================================================================================================
==>step: 858, f_score: 0.44160979986190796, recall: 0.9893876314163208, precision:0.2901444733142853, sAP10: 0.45598027695214394
 
epo: 142, steps: 858 ,sAP10 : 0.4560 , best sAP10: 4.8579
{'fscore': 0.4416098, 'recall': 0.98938763, 'precision': 0.29014447, 'sAP10': 0.45598027695214394}
====================================================================================================
==>step: 864, f_score: 0.4397263526916504, recall: 0.9960981011390686, precision:0.2874830961227417, sAP10: 0.789054245901061
 
epo: 143, steps: 864 ,sAP10 : 0.7891 , best sAP10: 4.8579
{'fscore': 0.43972635, 'recall': 0.9960981, 'precision': 0.2874831, 'sAP10': 0.789054245901061}
====================================================================================================
==>step: 870, f_score: 0.44646257162094116, recall: 0.9970315098762512, precision:0.29298439621925354, sAP10: 0.8275892826844674
 
epo: 144, steps: 870 ,sAP10 : 0.8276 , best sAP10: 4.8579
{'fscore': 0.44646257, 'recall': 0.9970315, 'precision': 0.2929844, 'sAP10': 0.8275892826844674}
====================================================================================================
==>step: 876, f_score: 0.4618566334247589, recall: 0.9938039183616638, precision:0.3063598871231079, sAP10: 0.827472061392541
 
epo: 145, steps: 876 ,sAP10 : 0.8275 , best sAP10: 4.8579
{'fscore': 0.46185663, 'recall': 0.9938039, 'precision': 0.3063599, 'sAP10': 0.827472061392541}
====================================================================================================
==>step: 882, f_score: 0.4604349732398987, recall: 0.9935972094535828, precision:0.3057352304458618, sAP10: 2.205634104790578
 
epo: 146, steps: 882 ,sAP10 : 2.2056 , best sAP10: 4.8579
{'fscore': 0.46043497, 'recall': 0.9935972, 'precision': 0.30573523, 'sAP10': 2.205634104790578}
====================================================================================================
==>step: 888, f_score: 0.4683835804462433, recall: 0.9916709661483765, precision:0.31265896558761597, sAP10: 1.3041065121490791
 
epo: 147, steps: 888 ,sAP10 : 1.3041 , best sAP10: 4.8579
{'fscore': 0.46838358, 'recall': 0.99167097, 'precision': 0.31265897, 'sAP10': 1.3041065121490791}
====================================================================================================
==>step: 894, f_score: 0.4721980690956116, recall: 0.9946638345718384, precision:0.31471890211105347, sAP10: 0.6402802316927847
 
epo: 148, steps: 894 ,sAP10 : 0.6403 , best sAP10: 4.8579
{'fscore': 0.47219807, 'recall': 0.99466383, 'precision': 0.3147189, 'sAP10': 0.6402802316927847}
====================================================================================================
==>step: 900, f_score: 0.4765927195549011, recall: 0.9954695105552673, precision:0.3187425434589386, sAP10: 0.6204394709067607
 
epo: 149, steps: 900 ,sAP10 : 0.6204 , best sAP10: 4.8579
{'fscore': 0.47659272, 'recall': 0.9954695, 'precision': 0.31874254, 'sAP10': 0.6204394709067607}
====================================================================================================
==>step: 906, f_score: 0.464141845703125, recall: 0.9961134195327759, precision:0.3076707124710083, sAP10: 1.819438800911624
 
epo: 150, steps: 906 ,sAP10 : 1.8194 , best sAP10: 4.8579
{'fscore': 0.46414185, 'recall': 0.9961134, 'precision': 0.3076707, 'sAP10': 1.819438800911624}
====================================================================================================
==>step: 912, f_score: 0.46427544951438904, recall: 0.9965141415596008, precision:0.3078917860984802, sAP10: 1.0112412755739757
 
epo: 151, steps: 912 ,sAP10 : 1.0112 , best sAP10: 4.8579
{'fscore': 0.46427545, 'recall': 0.99651414, 'precision': 0.3078918, 'sAP10': 1.0112412755739757}
====================================================================================================
==>step: 918, f_score: 0.4604245722293854, recall: 0.9968810677528381, precision:0.30457958579063416, sAP10: 1.0254757780683066
 
epo: 152, steps: 918 ,sAP10 : 1.0255 , best sAP10: 4.8579
{'fscore': 0.46042457, 'recall': 0.99688107, 'precision': 0.3045796, 'sAP10': 1.0254757780683066}
====================================================================================================
==>step: 924, f_score: 0.45851951837539673, recall: 0.9965026378631592, precision:0.30301088094711304, sAP10: 1.690374090005534
 
epo: 153, steps: 924 ,sAP10 : 1.6904 , best sAP10: 4.8579
{'fscore': 0.45851952, 'recall': 0.99650264, 'precision': 0.30301088, 'sAP10': 1.690374090005534}
====================================================================================================
==>step: 930, f_score: 0.4607812762260437, recall: 0.9957093000411987, precision:0.30516645312309265, sAP10: 1.6226321076346764
 
epo: 154, steps: 930 ,sAP10 : 1.6226 , best sAP10: 4.8579
{'fscore': 0.46078128, 'recall': 0.9957093, 'precision': 0.30516645, 'sAP10': 1.6226321076346764}
====================================================================================================
