using config:  mlsd_pytorch/configs/mobilev2_mlsd_tiny_512_base2_bsize16_lr001.yaml
datasets:
  input_size: 512
  name: wireframe
  with_centermap_extend: False
decode:
  len_thresh: 5
  score_thresh: 0.05
  top_k: 500
loss:
  focal_loss_level: 0
  loss_type: 1*L1
  loss_weight_dict_list: [{'tp_center_loss': 10.0, 'sol_center_loss': 1.0, 'tp_match_loss': 1.0}]
  match_sap_thresh: 5.0
  with_focal_loss: True
  with_match_loss: False
  with_sol_loss: True
model:
  model_name: mobilev2_mlsd
  num_classes: 1
  with_deconv: True
sys:
  cpu: False
  gpus: 1
  num_workers: 8
train:
  adam_epsilon: 1e-06
  batch_size: 16
  cache_to_mem: False
  data_cache_dir: ./data/wireframe_cache/
  device_ids: [0]
  device_ids_str: 0
  do_train: True
  dropout: 0.1
  early_stop_n: 200
  gradient_accumulation_steps: 1
  img_dir: ./data/wireframe_raw/images/
  label_fn: ./data/wireframe_raw/train.json
  learning_rate: 0.01
  load_from: 
  log_steps: 50
  lr_decay_gamma: 0.2
  milestones: [50, 100, 150]
  milestones_in_epo: True
  num_train_epochs: 155
  num_workers: 8
  save_dir: ./workdir/models/mobilev2_mlsd_tiny_512_bsize242023-10-13T13:57:55.590643/
  use_step_lr_policy: True
  warmup_steps: 100
  weight_decay: 1e-06
  with_cache: False
val:
  batch_size: 8
  img_dir: ./data/wireframe_raw/images/
  label_fn: ./data/wireframe_raw/valid.json
  val_after_epoch: 50
==> load label..
==> valid samples:  48
==> load label..
==> valid samples:  15
MobileV2_MLSD(
  (backbone): MobileNetV2(
    (features): Sequential(
      (0): ConvBNReLU(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): ConvBNReLU(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (1): ConvBNReLU(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
            (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (block12): BlockTypeA(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (block13): BlockTypeB(
    (conv1): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (block14): BlockTypeA(
    (conv1): Sequential(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (block15): BlockTypeB(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (block16): BlockTypeC(
    (conv1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(5, 5), dilation=(5, 5))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv3): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
  )
  (block17): BilinearConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
)
===> loss weight:  {'tp_center_loss': 10.0, 'tp_displacement_loss': 1.0, 'tp_len_loss': 1.0, 'tp_angle_loss': 1.0, 'tp_match_loss': 1.0, 'tp_centerness_loss': 1.0, 'sol_center_loss': 1.0, 'sol_displacement_loss': 1.0, 'sol_len_loss': 1.0, 'sol_angle_loss': 1.0, 'sol_match_loss': 1.0, 'sol_centerness_loss': 1.0, 'line_seg_loss': 1.0, 'junc_seg_loss': 1.0}
==>step: 156, f_score: 0.2870582342147827, recall: 0.9999989867210388, precision:0.16961535811424255, sAP10: 0.07324695846429582
 
epo: 51, steps: 156 ,sAP10 : 0.0732 , best sAP10: 0.0732
{'fscore': 0.28705823, 'recall': 0.999999, 'precision': 0.16961536, 'sAP10': 0.07324695846429582}
====================================================================================================
==>step: 159, f_score: 0.2830597162246704, recall: 0.9999989867210388, precision:0.16610540449619293, sAP10: 0.31637152532677226
 
epo: 52, steps: 159 ,sAP10 : 0.3164 , best sAP10: 0.3164
{'fscore': 0.28305972, 'recall': 0.999999, 'precision': 0.1661054, 'sAP10': 0.31637152532677226}
====================================================================================================
==>step: 162, f_score: 0.32541152834892273, recall: 0.999309778213501, precision:0.19689509272575378, sAP10: 0.4649317780385741
 
epo: 53, steps: 162 ,sAP10 : 0.4649 , best sAP10: 0.4649
{'fscore': 0.32541153, 'recall': 0.9993098, 'precision': 0.1968951, 'sAP10': 0.4649317780385741}
====================================================================================================
==>step: 165, f_score: 0.2963639497756958, recall: 0.9997326135635376, precision:0.17587962746620178, sAP10: 0.24134146442440652
 
epo: 54, steps: 165 ,sAP10 : 0.2413 , best sAP10: 0.4649
{'fscore': 0.29636395, 'recall': 0.9997326, 'precision': 0.17587963, 'sAP10': 0.24134146442440652}
====================================================================================================
==>step: 168, f_score: 0.3028971552848816, recall: 0.9999989867210388, precision:0.18092578649520874, sAP10: 0.20689075696455
 
epo: 55, steps: 168 ,sAP10 : 0.2069 , best sAP10: 0.4649
{'fscore': 0.30289716, 'recall': 0.999999, 'precision': 0.18092579, 'sAP10': 0.20689075696455}
====================================================================================================
==>step: 171, f_score: 0.3626177906990051, recall: 0.9997779130935669, precision:0.22425463795661926, sAP10: 0.5537136935336737
 
epo: 56, steps: 171 ,sAP10 : 0.5537 , best sAP10: 0.5537
{'fscore': 0.3626178, 'recall': 0.9997779, 'precision': 0.22425464, 'sAP10': 0.5537136935336737}
====================================================================================================
==>step: 174, f_score: 0.3961649537086487, recall: 0.9976933002471924, precision:0.24989131093025208, sAP10: 0.5249447110206076
 
epo: 57, steps: 174 ,sAP10 : 0.5249 , best sAP10: 0.5537
{'fscore': 0.39616495, 'recall': 0.9976933, 'precision': 0.24989131, 'sAP10': 0.5249447110206076}
====================================================================================================
==>step: 177, f_score: 0.4166756570339203, recall: 0.9902846813201904, precision:0.267428994178772, sAP10: 0.08936301793444651
 
epo: 58, steps: 177 ,sAP10 : 0.0894 , best sAP10: 0.5537
{'fscore': 0.41667566, 'recall': 0.9902847, 'precision': 0.267429, 'sAP10': 0.08936301793444651}
====================================================================================================
==>step: 180, f_score: 0.3894581198692322, recall: 0.9974205493927002, precision:0.2450706511735916, sAP10: 0.3156874802249206
 
epo: 59, steps: 180 ,sAP10 : 0.3157 , best sAP10: 0.5537
{'fscore': 0.38945812, 'recall': 0.99742055, 'precision': 0.24507065, 'sAP10': 0.3156874802249206}
====================================================================================================
==>step: 183, f_score: 0.4283491373062134, recall: 0.9975793361663818, precision:0.2768517732620239, sAP10: 0.48689689114590545
 
epo: 60, steps: 183 ,sAP10 : 0.4869 , best sAP10: 0.5537
{'fscore': 0.42834914, 'recall': 0.99757934, 'precision': 0.27685177, 'sAP10': 0.48689689114590545}
====================================================================================================
==>step: 186, f_score: 0.4224086403846741, recall: 0.9871485233306885, precision:0.2725297510623932, sAP10: 0.1286820596627779
 
epo: 61, steps: 186 ,sAP10 : 0.1287 , best sAP10: 0.5537
{'fscore': 0.42240864, 'recall': 0.9871485, 'precision': 0.27252975, 'sAP10': 0.1286820596627779}
====================================================================================================
==>step: 189, f_score: 0.4417409896850586, recall: 0.9986622333526611, precision:0.28797295689582825, sAP10: 0.31615146987512843
 
epo: 62, steps: 189 ,sAP10 : 0.3162 , best sAP10: 0.5537
{'fscore': 0.441741, 'recall': 0.99866223, 'precision': 0.28797296, 'sAP10': 0.31615146987512843}
====================================================================================================
==>step: 192, f_score: 0.4889873266220093, recall: 0.9991549849510193, precision:0.32867786288261414, sAP10: 0.8710989390935129
 
epo: 63, steps: 192 ,sAP10 : 0.8711 , best sAP10: 0.8711
{'fscore': 0.48898733, 'recall': 0.999155, 'precision': 0.32867786, 'sAP10': 0.8710989390935129}
====================================================================================================
==>step: 195, f_score: 0.4739709198474884, recall: 0.9990211129188538, precision:0.315079003572464, sAP10: 0.9161131851226084
 
epo: 64, steps: 195 ,sAP10 : 0.9161 , best sAP10: 0.9161
{'fscore': 0.47397092, 'recall': 0.9990211, 'precision': 0.315079, 'sAP10': 0.9161131851226084}
====================================================================================================
==>step: 198, f_score: 0.47051775455474854, recall: 0.998028576374054, precision:0.31272199749946594, sAP10: 0.5377347792373812
 
epo: 65, steps: 198 ,sAP10 : 0.5377 , best sAP10: 0.9161
{'fscore': 0.47051775, 'recall': 0.9980286, 'precision': 0.312722, 'sAP10': 0.5377347792373812}
====================================================================================================
==>step: 201, f_score: 0.4616747796535492, recall: 0.9977229833602905, precision:0.30650514364242554, sAP10: 0.3030549951888527
 
epo: 66, steps: 201 ,sAP10 : 0.3031 , best sAP10: 0.9161
{'fscore': 0.46167478, 'recall': 0.997723, 'precision': 0.30650514, 'sAP10': 0.3030549951888527}
====================================================================================================
==>step: 204, f_score: 0.4515414834022522, recall: 0.995719313621521, precision:0.2970261871814728, sAP10: 0.4812598446004053
 
epo: 67, steps: 204 ,sAP10 : 0.4813 , best sAP10: 0.9161
{'fscore': 0.45154148, 'recall': 0.9957193, 'precision': 0.2970262, 'sAP10': 0.4812598446004053}
====================================================================================================
==>step: 207, f_score: 0.48436471819877625, recall: 0.9907451272010803, precision:0.32479870319366455, sAP10: 0.5248263156968777
 
epo: 68, steps: 207 ,sAP10 : 0.5248 , best sAP10: 0.9161
{'fscore': 0.48436472, 'recall': 0.9907451, 'precision': 0.3247987, 'sAP10': 0.5248263156968777}
====================================================================================================
==>step: 210, f_score: 0.49316370487213135, recall: 0.9954468011856079, precision:0.3326149880886078, sAP10: 0.22131656005345235
 
epo: 69, steps: 210 ,sAP10 : 0.2213 , best sAP10: 0.9161
{'fscore': 0.4931637, 'recall': 0.9954468, 'precision': 0.332615, 'sAP10': 0.22131656005345235}
====================================================================================================
==>step: 213, f_score: 0.48512139916419983, recall: 0.9955816864967346, precision:0.3260596692562103, sAP10: 0.08578880794539248
 
epo: 70, steps: 213 ,sAP10 : 0.0858 , best sAP10: 0.9161
{'fscore': 0.4851214, 'recall': 0.9955817, 'precision': 0.32605967, 'sAP10': 0.08578880794539248}
====================================================================================================
==>step: 216, f_score: 0.473458468914032, recall: 0.999301552772522, precision:0.3166259229183197, sAP10: 0.7828753809716762
 
epo: 71, steps: 216 ,sAP10 : 0.7829 , best sAP10: 0.9161
{'fscore': 0.47345847, 'recall': 0.99930155, 'precision': 0.31662592, 'sAP10': 0.7828753809716762}
====================================================================================================
==>step: 219, f_score: 0.48577314615249634, recall: 0.9948650002479553, precision:0.3270949721336365, sAP10: 0.6731738753850106
 
epo: 72, steps: 219 ,sAP10 : 0.6732 , best sAP10: 0.9161
{'fscore': 0.48577315, 'recall': 0.994865, 'precision': 0.32709497, 'sAP10': 0.6731738753850106}
====================================================================================================
==>step: 222, f_score: 0.5163777470588684, recall: 0.9897080063819885, precision:0.3546491265296936, sAP10: 0.657689400912536
 
epo: 73, steps: 222 ,sAP10 : 0.6577 , best sAP10: 0.9161
{'fscore': 0.51637775, 'recall': 0.989708, 'precision': 0.35464913, 'sAP10': 0.657689400912536}
====================================================================================================
==>step: 225, f_score: 0.4854191243648529, recall: 0.9947877526283264, precision:0.3270680606365204, sAP10: 0.057556201454915676
 
epo: 74, steps: 225 ,sAP10 : 0.0576 , best sAP10: 0.9161
{'fscore': 0.48541912, 'recall': 0.99478775, 'precision': 0.32706806, 'sAP10': 0.057556201454915676}
====================================================================================================
==>step: 228, f_score: 0.5134767293930054, recall: 0.9975597858428955, precision:0.3513554632663727, sAP10: 0.28118438050941613
 
epo: 75, steps: 228 ,sAP10 : 0.2812 , best sAP10: 0.9161
{'fscore': 0.5134767, 'recall': 0.9975598, 'precision': 0.35135546, 'sAP10': 0.28118438050941613}
====================================================================================================
==>step: 231, f_score: 0.4934081733226776, recall: 0.9961642622947693, precision:0.33277252316474915, sAP10: 0.4999963654218046
 
epo: 76, steps: 231 ,sAP10 : 0.5000 , best sAP10: 0.9161
{'fscore': 0.49340817, 'recall': 0.99616426, 'precision': 0.33277252, 'sAP10': 0.4999963654218046}
====================================================================================================
==>step: 234, f_score: 0.48071667551994324, recall: 0.9985639452934265, precision:0.3224600553512573, sAP10: 0.4163517006452431
 
epo: 77, steps: 234 ,sAP10 : 0.4164 , best sAP10: 0.9161
{'fscore': 0.48071668, 'recall': 0.99856395, 'precision': 0.32246006, 'sAP10': 0.4163517006452431}
====================================================================================================
==>step: 237, f_score: 0.502403199672699, recall: 0.9975244402885437, precision:0.34240007400512695, sAP10: 1.3803847645263962
 
epo: 78, steps: 237 ,sAP10 : 1.3804 , best sAP10: 1.3804
{'fscore': 0.5024032, 'recall': 0.99752444, 'precision': 0.34240007, 'sAP10': 1.3803847645263962}
====================================================================================================
==>step: 240, f_score: 0.517869770526886, recall: 0.9933750033378601, precision:0.3555739223957062, sAP10: 0.1191774676812603
 
epo: 79, steps: 240 ,sAP10 : 0.1192 , best sAP10: 1.3804
{'fscore': 0.5178698, 'recall': 0.993375, 'precision': 0.35557392, 'sAP10': 0.1191774676812603}
====================================================================================================
==>step: 243, f_score: 0.5313489437103271, recall: 0.9976869225502014, precision:0.3673737347126007, sAP10: 0.2628444546223566
 
epo: 80, steps: 243 ,sAP10 : 0.2628 , best sAP10: 1.3804
{'fscore': 0.53134894, 'recall': 0.9976869, 'precision': 0.36737373, 'sAP10': 0.2628444546223566}
====================================================================================================
==>step: 246, f_score: 0.5300418138504028, recall: 0.9948485493659973, precision:0.36580052971839905, sAP10: 0.3674837785769422
 
epo: 81, steps: 246 ,sAP10 : 0.3675 , best sAP10: 1.3804
{'fscore': 0.5300418, 'recall': 0.99484855, 'precision': 0.36580053, 'sAP10': 0.3674837785769422}
====================================================================================================
==>step: 249, f_score: 0.4885905086994171, recall: 0.9966825842857361, precision:0.3291841447353363, sAP10: 0.20769094708675734
 
epo: 82, steps: 249 ,sAP10 : 0.2077 , best sAP10: 1.3804
{'fscore': 0.4885905, 'recall': 0.9966826, 'precision': 0.32918414, 'sAP10': 0.20769094708675734}
====================================================================================================
==>step: 252, f_score: 0.4939645230770111, recall: 0.9994644522666931, precision:0.33350297808647156, sAP10: 0.3040490651061423
 
epo: 83, steps: 252 ,sAP10 : 0.3040 , best sAP10: 1.3804
{'fscore': 0.49396452, 'recall': 0.99946445, 'precision': 0.33350298, 'sAP10': 0.3040490651061423}
====================================================================================================
==>step: 255, f_score: 0.49606508016586304, recall: 0.9962151646614075, precision:0.335593581199646, sAP10: 0.31254864358302864
 
epo: 84, steps: 255 ,sAP10 : 0.3125 , best sAP10: 1.3804
{'fscore': 0.49606508, 'recall': 0.99621516, 'precision': 0.33559358, 'sAP10': 0.31254864358302864}
====================================================================================================
==>step: 258, f_score: 0.48418715596199036, recall: 0.9808038473129272, precision:0.32582932710647583, sAP10: 0.03167074248928096
 
epo: 85, steps: 258 ,sAP10 : 0.0317 , best sAP10: 1.3804
{'fscore': 0.48418716, 'recall': 0.98080385, 'precision': 0.32582933, 'sAP10': 0.03167074248928096}
====================================================================================================
==>step: 261, f_score: 0.49345487356185913, recall: 0.9216629862785339, precision:0.347703754901886, sAP10: 0.036449147560258674
 
epo: 86, steps: 261 ,sAP10 : 0.0364 , best sAP10: 1.3804
{'fscore': 0.49345487, 'recall': 0.921663, 'precision': 0.34770375, 'sAP10': 0.036449147560258674}
====================================================================================================
==>step: 264, f_score: 0.4830799400806427, recall: 0.9980204701423645, precision:0.3241928517818451, sAP10: 0.654308941551512
 
epo: 87, steps: 264 ,sAP10 : 0.6543 , best sAP10: 1.3804
{'fscore': 0.48307994, 'recall': 0.99802047, 'precision': 0.32419285, 'sAP10': 0.654308941551512}
====================================================================================================
==>step: 267, f_score: 0.4963977038860321, recall: 0.994218647480011, precision:0.33620786666870117, sAP10: 0.31250433215498713
 
epo: 88, steps: 267 ,sAP10 : 0.3125 , best sAP10: 1.3804
{'fscore': 0.4963977, 'recall': 0.99421865, 'precision': 0.33620787, 'sAP10': 0.31250433215498713}
====================================================================================================
==>step: 270, f_score: 0.4645802676677704, recall: 0.9834358096122742, precision:0.30810290575027466, sAP10: 0.00315357931251971
 
epo: 89, steps: 270 ,sAP10 : 0.0032 , best sAP10: 1.3804
{'fscore': 0.46458027, 'recall': 0.9834358, 'precision': 0.3081029, 'sAP10': 0.00315357931251971}
====================================================================================================
==>step: 273, f_score: 0.4497259259223938, recall: 0.9992383122444153, precision:0.29538407921791077, sAP10: 0.34843829709279234
 
epo: 90, steps: 273 ,sAP10 : 0.3484 , best sAP10: 1.3804
{'fscore': 0.44972593, 'recall': 0.9992383, 'precision': 0.29538408, 'sAP10': 0.34843829709279234}
====================================================================================================
==>step: 276, f_score: 0.48568180203437805, recall: 0.9963912963867188, precision:0.32603129744529724, sAP10: 0.725210127525358
 
epo: 91, steps: 276 ,sAP10 : 0.7252 , best sAP10: 1.3804
{'fscore': 0.4856818, 'recall': 0.9963913, 'precision': 0.3260313, 'sAP10': 0.725210127525358}
====================================================================================================
==>step: 279, f_score: 0.5140622854232788, recall: 0.9929993748664856, precision:0.35171744227409363, sAP10: 0.08411356918646554
 
epo: 92, steps: 279 ,sAP10 : 0.0841 , best sAP10: 1.3804
{'fscore': 0.5140623, 'recall': 0.9929994, 'precision': 0.35171744, 'sAP10': 0.08411356918646554}
====================================================================================================
==>step: 282, f_score: 0.525382936000824, recall: 0.9959879517555237, precision:0.36220061779022217, sAP10: 0.503589547305075
 
epo: 93, steps: 282 ,sAP10 : 0.5036 , best sAP10: 1.3804
{'fscore': 0.52538294, 'recall': 0.99598795, 'precision': 0.36220062, 'sAP10': 0.503589547305075}
====================================================================================================
==>step: 285, f_score: 0.5450114607810974, recall: 0.9929954409599304, precision:0.38094809651374817, sAP10: 1.2435833363805462
 
epo: 94, steps: 285 ,sAP10 : 1.2436 , best sAP10: 1.3804
{'fscore': 0.54501146, 'recall': 0.99299544, 'precision': 0.3809481, 'sAP10': 1.2435833363805462}
====================================================================================================
==>step: 288, f_score: 0.500166654586792, recall: 0.9921880960464478, precision:0.33898767828941345, sAP10: 1.169206193429765
 
epo: 95, steps: 288 ,sAP10 : 1.1692 , best sAP10: 1.3804
{'fscore': 0.50016665, 'recall': 0.9921881, 'precision': 0.33898768, 'sAP10': 1.169206193429765}
====================================================================================================
==>step: 291, f_score: 0.49549606442451477, recall: 0.9977725148200989, precision:0.3339484632015228, sAP10: 1.0746700955010136
 
epo: 96, steps: 291 ,sAP10 : 1.0747 , best sAP10: 1.3804
{'fscore': 0.49549606, 'recall': 0.9977725, 'precision': 0.33394846, 'sAP10': 1.0746700955010136}
====================================================================================================
==>step: 294, f_score: 0.4764496982097626, recall: 0.9954789876937866, precision:0.31741178035736084, sAP10: 0.1795900910342327
 
epo: 97, steps: 294 ,sAP10 : 0.1796 , best sAP10: 1.3804
{'fscore': 0.4764497, 'recall': 0.995479, 'precision': 0.31741178, 'sAP10': 0.1795900910342327}
====================================================================================================
==>step: 297, f_score: 0.5008178353309631, recall: 0.9988968968391418, precision:0.338992178440094, sAP10: 0.3535873754248221
 
epo: 98, steps: 297 ,sAP10 : 0.3536 , best sAP10: 1.3804
{'fscore': 0.50081784, 'recall': 0.9988969, 'precision': 0.33899218, 'sAP10': 0.3535873754248221}
====================================================================================================
==>step: 300, f_score: 0.48342689871788025, recall: 0.9947433471679688, precision:0.32308873534202576, sAP10: 0.08380450161204296
 
epo: 99, steps: 300 ,sAP10 : 0.0838 , best sAP10: 1.3804
{'fscore': 0.4834269, 'recall': 0.99474335, 'precision': 0.32308874, 'sAP10': 0.08380450161204296}
====================================================================================================
==>step: 303, f_score: 0.4909310042858124, recall: 0.9950906038284302, precision:0.3298770785331726, sAP10: 0.3151139498433104
 
epo: 100, steps: 303 ,sAP10 : 0.3151 , best sAP10: 1.3804
{'fscore': 0.490931, 'recall': 0.9950906, 'precision': 0.32987708, 'sAP10': 0.3151139498433104}
====================================================================================================
==>step: 306, f_score: 0.5022527575492859, recall: 0.9952533841133118, precision:0.3402467668056488, sAP10: 0.4048196471228495
 
epo: 101, steps: 306 ,sAP10 : 0.4048 , best sAP10: 1.3804
{'fscore': 0.50225276, 'recall': 0.9952534, 'precision': 0.34024677, 'sAP10': 0.4048196471228495}
====================================================================================================
==>step: 309, f_score: 0.5018749237060547, recall: 0.9971693754196167, precision:0.33983781933784485, sAP10: 0.9995906567640739
 
epo: 102, steps: 309 ,sAP10 : 0.9996 , best sAP10: 1.3804
{'fscore': 0.5018749, 'recall': 0.9971694, 'precision': 0.33983782, 'sAP10': 0.9995906567640739}
====================================================================================================
==>step: 312, f_score: 0.5121204257011414, recall: 0.9980038404464722, precision:0.34940001368522644, sAP10: 0.3680451765600102
 
epo: 103, steps: 312 ,sAP10 : 0.3680 , best sAP10: 1.3804
{'fscore': 0.5121204, 'recall': 0.99800384, 'precision': 0.3494, 'sAP10': 0.3680451765600102}
====================================================================================================
==>step: 315, f_score: 0.514055073261261, recall: 0.9969748258590698, precision:0.35163941979408264, sAP10: 0.2425961663367646
 
epo: 104, steps: 315 ,sAP10 : 0.2426 , best sAP10: 1.3804
{'fscore': 0.5140551, 'recall': 0.9969748, 'precision': 0.35163942, 'sAP10': 0.2425961663367646}
====================================================================================================
==>step: 318, f_score: 0.5150521397590637, recall: 0.9970085620880127, precision:0.35150137543678284, sAP10: 0.3613969473139574
 
epo: 105, steps: 318 ,sAP10 : 0.3614 , best sAP10: 1.3804
{'fscore': 0.51505214, 'recall': 0.99700856, 'precision': 0.35150138, 'sAP10': 0.3613969473139574}
====================================================================================================
==>step: 321, f_score: 0.5198006629943848, recall: 0.997665286064148, precision:0.35562852025032043, sAP10: 0.8878989335765243
 
epo: 106, steps: 321 ,sAP10 : 0.8879 , best sAP10: 1.3804
{'fscore': 0.51980066, 'recall': 0.9976653, 'precision': 0.35562852, 'sAP10': 0.8878989335765243}
====================================================================================================
==>step: 324, f_score: 0.5353743433952332, recall: 0.9971010684967041, precision:0.3707176446914673, sAP10: 0.6464528810115151
 
epo: 107, steps: 324 ,sAP10 : 0.6465 , best sAP10: 1.3804
{'fscore': 0.53537434, 'recall': 0.99710107, 'precision': 0.37071764, 'sAP10': 0.6464528810115151}
====================================================================================================
==>step: 327, f_score: 0.5391302108764648, recall: 0.9967040419578552, precision:0.37445804476737976, sAP10: 0.7125150710668715
 
epo: 108, steps: 327 ,sAP10 : 0.7125 , best sAP10: 1.3804
{'fscore': 0.5391302, 'recall': 0.99670404, 'precision': 0.37445804, 'sAP10': 0.7125150710668715}
====================================================================================================
==>step: 330, f_score: 0.5450696349143982, recall: 0.9938734769821167, precision:0.3805476427078247, sAP10: 0.425035578430045
 
epo: 109, steps: 330 ,sAP10 : 0.4250 , best sAP10: 1.3804
{'fscore': 0.54506963, 'recall': 0.9938735, 'precision': 0.38054764, 'sAP10': 0.425035578430045}
====================================================================================================
==>step: 333, f_score: 0.5322220325469971, recall: 0.9939295053482056, precision:0.3683859705924988, sAP10: 0.9073253718339919
 
epo: 110, steps: 333 ,sAP10 : 0.9073 , best sAP10: 1.3804
{'fscore': 0.53222203, 'recall': 0.9939295, 'precision': 0.36838597, 'sAP10': 0.9073253718339919}
====================================================================================================
==>step: 336, f_score: 0.5168739557266235, recall: 0.993985116481781, precision:0.3543354570865631, sAP10: 1.0140476535052731
 
epo: 111, steps: 336 ,sAP10 : 1.0140 , best sAP10: 1.3804
{'fscore': 0.51687396, 'recall': 0.9939851, 'precision': 0.35433546, 'sAP10': 1.0140476535052731}
====================================================================================================
==>step: 339, f_score: 0.5195340514183044, recall: 0.9956463575363159, precision:0.3565181791782379, sAP10: 0.6487047020065887
 
epo: 112, steps: 339 ,sAP10 : 0.6487 , best sAP10: 1.3804
{'fscore': 0.51953405, 'recall': 0.99564636, 'precision': 0.35651818, 'sAP10': 0.6487047020065887}
====================================================================================================
==>step: 342, f_score: 0.5164667367935181, recall: 0.9954278469085693, precision:0.35327547788619995, sAP10: 1.5204422022927597
 
epo: 113, steps: 342 ,sAP10 : 1.5204 , best sAP10: 1.5204
{'fscore': 0.51646674, 'recall': 0.99542785, 'precision': 0.35327548, 'sAP10': 1.5204422022927597}
====================================================================================================
==>step: 345, f_score: 0.5163153409957886, recall: 0.9943773746490479, precision:0.35310038924217224, sAP10: 1.4808824050145175
 
epo: 114, steps: 345 ,sAP10 : 1.4809 , best sAP10: 1.5204
{'fscore': 0.51631534, 'recall': 0.9943774, 'precision': 0.3531004, 'sAP10': 1.4808824050145175}
====================================================================================================
==>step: 348, f_score: 0.51534503698349, recall: 0.9970195293426514, precision:0.3517436385154724, sAP10: 1.0531351033283165
 
epo: 115, steps: 348 ,sAP10 : 1.0531 , best sAP10: 1.5204
{'fscore': 0.51534504, 'recall': 0.9970195, 'precision': 0.35174364, 'sAP10': 1.0531351033283165}
====================================================================================================
==>step: 351, f_score: 0.519280731678009, recall: 0.9983804225921631, precision:0.35572707653045654, sAP10: 0.9965703334435203
 
epo: 116, steps: 351 ,sAP10 : 0.9966 , best sAP10: 1.5204
{'fscore': 0.51928073, 'recall': 0.9983804, 'precision': 0.35572708, 'sAP10': 0.9965703334435203}
====================================================================================================
==>step: 354, f_score: 0.5242607593536377, recall: 0.9975693225860596, precision:0.3611246347427368, sAP10: 0.8522807017384757
 
epo: 117, steps: 354 ,sAP10 : 0.8523 , best sAP10: 1.5204
{'fscore': 0.52426076, 'recall': 0.9975693, 'precision': 0.36112463, 'sAP10': 0.8522807017384757}
====================================================================================================
==>step: 357, f_score: 0.5281309485435486, recall: 0.9950907230377197, precision:0.36511895060539246, sAP10: 1.3579579579579577
 
epo: 118, steps: 357 ,sAP10 : 1.3580 , best sAP10: 1.5204
{'fscore': 0.52813095, 'recall': 0.9950907, 'precision': 0.36511895, 'sAP10': 1.3579579579579577}
====================================================================================================
==>step: 360, f_score: 0.5278836488723755, recall: 0.9959664940834045, precision:0.3647930324077606, sAP10: 2.0247618380648866
 
epo: 119, steps: 360 ,sAP10 : 2.0248 , best sAP10: 2.0248
{'fscore': 0.52788365, 'recall': 0.9959665, 'precision': 0.36479303, 'sAP10': 2.0247618380648866}
====================================================================================================
==>step: 363, f_score: 0.5278422236442566, recall: 0.9962023496627808, precision:0.36477959156036377, sAP10: 1.6777619075844457
 
epo: 120, steps: 363 ,sAP10 : 1.6778 , best sAP10: 2.0248
{'fscore': 0.5278422, 'recall': 0.99620235, 'precision': 0.3647796, 'sAP10': 1.6777619075844457}
====================================================================================================
==>step: 366, f_score: 0.5284996628761292, recall: 0.998764157295227, precision:0.3648332953453064, sAP10: 1.711960960834729
 
epo: 121, steps: 366 ,sAP10 : 1.7120 , best sAP10: 2.0248
{'fscore': 0.52849966, 'recall': 0.99876416, 'precision': 0.3648333, 'sAP10': 1.711960960834729}
====================================================================================================
==>step: 369, f_score: 0.5236528515815735, recall: 0.9993959069252014, precision:0.36062291264533997, sAP10: 1.7836035860664419
 
epo: 122, steps: 369 ,sAP10 : 1.7836 , best sAP10: 2.0248
{'fscore': 0.52365285, 'recall': 0.9993959, 'precision': 0.3606229, 'sAP10': 1.7836035860664419}
====================================================================================================
==>step: 372, f_score: 0.5182898044586182, recall: 0.9963996410369873, precision:0.35564950108528137, sAP10: 1.363666583081313
 
epo: 123, steps: 372 ,sAP10 : 1.3637 , best sAP10: 2.0248
{'fscore': 0.5182898, 'recall': 0.99639964, 'precision': 0.3556495, 'sAP10': 1.363666583081313}
====================================================================================================
==>step: 375, f_score: 0.5243155360221863, recall: 0.9960489273071289, precision:0.3613024950027466, sAP10: 0.9177675730883538
 
epo: 124, steps: 375 ,sAP10 : 0.9178 , best sAP10: 2.0248
{'fscore': 0.52431554, 'recall': 0.9960489, 'precision': 0.3613025, 'sAP10': 0.9177675730883538}
====================================================================================================
==>step: 378, f_score: 0.522181510925293, recall: 0.9966742396354675, precision:0.35884132981300354, sAP10: 0.9538888528682151
 
epo: 125, steps: 378 ,sAP10 : 0.9539 , best sAP10: 2.0248
{'fscore': 0.5221815, 'recall': 0.99667424, 'precision': 0.35884133, 'sAP10': 0.9538888528682151}
====================================================================================================
==>step: 381, f_score: 0.5234000086784363, recall: 0.9976465106010437, precision:0.3600165545940399, sAP10: 2.0725869135216994
 
epo: 126, steps: 381 ,sAP10 : 2.0726 , best sAP10: 2.0726
{'fscore': 0.5234, 'recall': 0.9976465, 'precision': 0.36001655, 'sAP10': 2.0725869135216994}
====================================================================================================
==>step: 384, f_score: 0.5247182250022888, recall: 0.9964268207550049, precision:0.36099112033843994, sAP10: 3.6312624733691496
 
epo: 127, steps: 384 ,sAP10 : 3.6313 , best sAP10: 3.6313
{'fscore': 0.5247182, 'recall': 0.9964268, 'precision': 0.36099112, 'sAP10': 3.6312624733691496}
====================================================================================================
==>step: 387, f_score: 0.5279775857925415, recall: 0.9972830414772034, precision:0.36355260014533997, sAP10: 0.9863643604566443
 
epo: 128, steps: 387 ,sAP10 : 0.9864 , best sAP10: 3.6313
{'fscore': 0.5279776, 'recall': 0.99728304, 'precision': 0.3635526, 'sAP10': 0.9863643604566443}
====================================================================================================
==>step: 390, f_score: 0.5204765200614929, recall: 0.9989509582519531, precision:0.35658395290374756, sAP10: 1.0197739302602953
 
epo: 129, steps: 390 ,sAP10 : 1.0198 , best sAP10: 3.6313
{'fscore': 0.5204765, 'recall': 0.99895096, 'precision': 0.35658395, 'sAP10': 1.0197739302602953}
====================================================================================================
==>step: 393, f_score: 0.502844512462616, recall: 0.9990283250808716, precision:0.33989816904067993, sAP10: 0.987710702190385
 
epo: 130, steps: 393 ,sAP10 : 0.9877 , best sAP10: 3.6313
{'fscore': 0.5028445, 'recall': 0.9990283, 'precision': 0.33989817, 'sAP10': 0.987710702190385}
====================================================================================================
==>step: 396, f_score: 0.4966863691806793, recall: 0.9972302913665771, precision:0.33436286449432373, sAP10: 0.8532531714789691
 
epo: 131, steps: 396 ,sAP10 : 0.8533 , best sAP10: 3.6313
{'fscore': 0.49668637, 'recall': 0.9972303, 'precision': 0.33436286, 'sAP10': 0.8532531714789691}
====================================================================================================
==>step: 399, f_score: 0.4982481598854065, recall: 0.9970420002937317, precision:0.3360501825809479, sAP10: 1.0446948869119632
 
epo: 132, steps: 399 ,sAP10 : 1.0447 , best sAP10: 3.6313
{'fscore': 0.49824816, 'recall': 0.997042, 'precision': 0.33605018, 'sAP10': 1.0446948869119632}
====================================================================================================
==>step: 402, f_score: 0.5004037022590637, recall: 0.9963077902793884, precision:0.338161438703537, sAP10: 1.0841222670803383
 
epo: 133, steps: 402 ,sAP10 : 1.0841 , best sAP10: 3.6313
{'fscore': 0.5004037, 'recall': 0.9963078, 'precision': 0.33816144, 'sAP10': 1.0841222670803383}
====================================================================================================
==>step: 405, f_score: 0.5035887956619263, recall: 0.9976896047592163, precision:0.3403530418872833, sAP10: 2.311291615937616
 
epo: 134, steps: 405 ,sAP10 : 2.3113 , best sAP10: 3.6313
{'fscore': 0.5035888, 'recall': 0.9976896, 'precision': 0.34035304, 'sAP10': 2.311291615937616}
====================================================================================================
==>step: 408, f_score: 0.5063700675964355, recall: 0.9988126754760742, precision:0.3429481089115143, sAP10: 1.4374338253956207
 
epo: 135, steps: 408 ,sAP10 : 1.4374 , best sAP10: 3.6313
{'fscore': 0.50637007, 'recall': 0.9988127, 'precision': 0.3429481, 'sAP10': 1.4374338253956207}
====================================================================================================
==>step: 411, f_score: 0.5040671229362488, recall: 0.9987662434577942, precision:0.3410431146621704, sAP10: 1.4519454318461378
 
epo: 136, steps: 411 ,sAP10 : 1.4519 , best sAP10: 3.6313
{'fscore': 0.5040671, 'recall': 0.99876624, 'precision': 0.3410431, 'sAP10': 1.4519454318461378}
====================================================================================================
==>step: 414, f_score: 0.5124014019966125, recall: 0.9974706768989563, precision:0.3486970365047455, sAP10: 1.3603217685305373
 
epo: 137, steps: 414 ,sAP10 : 1.3603 , best sAP10: 3.6313
{'fscore': 0.5124014, 'recall': 0.9974707, 'precision': 0.34869704, 'sAP10': 1.3603217685305373}
====================================================================================================
==>step: 417, f_score: 0.5379727482795715, recall: 0.9979323148727417, precision:0.37282583117485046, sAP10: 1.7945513720363646
 
epo: 138, steps: 417 ,sAP10 : 1.7946 , best sAP10: 3.6313
{'fscore': 0.53797275, 'recall': 0.9979323, 'precision': 0.37282583, 'sAP10': 1.7945513720363646}
====================================================================================================
